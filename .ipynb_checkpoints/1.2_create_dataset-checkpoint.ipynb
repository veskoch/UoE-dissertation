{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import magenta\n",
    "\n",
    "from magenta.pipelines import pipeline\n",
    "from magenta.protobuf import music_pb2\n",
    "from magenta.protobuf import generator_pb2\n",
    "\n",
    "import arrangement_create_dataset\n",
    "import arrangement_model\n",
    "\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run data through the following pipelines\n",
    "\n",
    "The fields below are inside `performance_rnn_create_dataset`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dag[sustain_pipeline] = partitioner[mode + '_performances']\n",
    "dag[stretch_pipeline] = sustain_pipeline\n",
    "dag[splitter] = stretch_pipeline\n",
    "dag[quantizer] = splitter\n",
    "dag[transposition_pipeline] = quantizer\n",
    "dag[perf_extractor] = transposition_pipeline\n",
    "\n",
    "dag[encoder_pipeline] = perf_extractor\n",
    "    input_type = music_pb2.NoteSequence\n",
    "    output_type = magenta.music.Performance\n",
    "\n",
    "dag[dag_pipeline.DagOutput(mode + '_performances')] = encoder_pipeline\n",
    "    input_type = magenta.music.Performance\n",
    "    output_type = tf.train.SequenceExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_graph():\n",
    "    pipeline_instance = arrangement_create_dataset.get_pipeline(\n",
    "        min_events = 32,\n",
    "        max_events = 512,\n",
    "        eval_ratio = EVAL_RATIO,\n",
    "        config = arrangement_model.default_configs[CONFIG])\n",
    "\n",
    "    # Runs the a pipeline on a data source and writes to a directory\n",
    "    pipeline.run_pipeline_serial(\n",
    "        pipeline_instance,\n",
    "        pipeline.tf_record_iterator(TFRECORD_FILE, pipeline_instance.input_type),\n",
    "        OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "WARNING:tensorflow:Chord symbols ignored by TranspositionPipeline.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 2 inputs total. Produced 43 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_performance_lengths_in_seconds:\n",
      "  [20,30): 1\n",
      "  [30,40): 7\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_training_performance_lengths_in_seconds:\n",
      "  [10,20): 35\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_training_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_training_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_training_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_training_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_eval_performances_count: 1\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_training_performances_count: 1\n",
      "INFO:tensorflow:DAGPipeline_TranspositionPipeline_eval_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_TranspositionPipeline_eval_transpositions_generated: 8\n",
      "INFO:tensorflow:DAGPipeline_TranspositionPipeline_training_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_TranspositionPipeline_training_transpositions_generated: 35\n"
     ]
    }
   ],
   "source": [
    "run_pipeline_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IO\n",
    "\n",
    "Reading the .tfrecord file without defining a computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_performances_dir = OUTPUT_DIR + 'training_performances.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = list()\n",
    "for record in pipeline.tf_record_iterator(training_performances_dir, tf.train.SequenceExample):\n",
    "    records.append(record)\n",
    "\n",
    "# len(records)\n",
    "# records[0].feature_lists.feature_list['inputs'].feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.models.performance_rnn import performance_model\n",
    "from magenta.pipelines import note_sequence_pipelines\n",
    "\n",
    "default_configs = {\n",
    "    'performance': performance_model.PerformanceRnnConfig(\n",
    "        magenta.protobuf.generator_pb2.GeneratorDetails(\n",
    "            id='performance',\n",
    "            description='Performance RNN'),\n",
    "        magenta.music.OneHotEventSequenceEncoderDecoder(\n",
    "            magenta.music.PerformanceOneHotEncoding()),\n",
    "        tf.contrib.training.HParams(\n",
    "            batch_size=64,\n",
    "            rnn_layer_sizes=[512, 512, 512],\n",
    "            dropout_keep_prob=1.0,\n",
    "            clip_norm=3,\n",
    "            learning_rate=0.001))\n",
    "}\n",
    "\n",
    "config = default_configs['performance']\n",
    "\n",
    "quantizer_instance = note_sequence_pipelines.Quantizer(steps_per_second = config.steps_per_second,\n",
    "                                                       name='Quantizer_jupyter')\n",
    "perf_extractor_instance = arrangement_create_dataset.PerformanceExtractor(min_events=32,\n",
    "                                                                          max_events=512,\n",
    "                                                                          num_velocity_bins = config.num_velocity_bins)\n",
    "encoder_pipeline_instance = arrangement_create_dataset.EncoderPipeline(config,\n",
    "                                                                       name='EncoderPipeline_jupyter')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in pipeline.tf_record_iterator(TFRECORD_FILE, music_pb2.NoteSequence):\n",
    "    note_sequence1 = record\n",
    "# note_sequence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence2 = quantizer_instance.transform(note_sequence1)[0]\n",
    "# note_sequence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance_lengths_in_bars: 0\n"
     ]
    }
   ],
   "source": [
    "note_sequence3 = perf_extractor_instance.transform(note_sequence2)[0]\n",
    "\n",
    "# converts Performance to NoteSequence proto\n",
    "note_sequence3.to_sequence()\n",
    "\n",
    "# returns an event at position\n",
    "note_sequence3.__getitem__(0) \n",
    "\n",
    "# returns an iterator\n",
    "# for i, event in enumerate(note_sequence3.__iter__()): \n",
    "#     print(event)\n",
    "#     if i > 25:\n",
    "#         break\n",
    "\n",
    "print(perf_extractor_instance.get_stats()[0]._pretty_print('performance_lengths_in_bars'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence4 = encoder_pipeline_instance.transform(note_sequence3)[0]\n",
    "# note_sequence4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining which position is 1 in the one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_event_ranges = [\n",
    "    (1, 1, 127),\n",
    "    (2, 1, 127),\n",
    "    (3, 1, 100)\n",
    "]\n",
    "\n",
    "def encode_event(event):\n",
    "    offset = 0\n",
    "    for event_type, min_value, max_value in _event_ranges:\n",
    "        if event[0] == event_type:\n",
    "            return offset + event[1] - min_value\n",
    "        offset += max_value - min_value + 1\n",
    "\n",
    "encode_event((3, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate time-shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
