{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.scripts import convert_dir_to_note_sequences\n",
    "import constants\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. This notebook will help you manage the data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "* Put all song `.xml` files in a single folder. Each song must have at least two peforming levels of difficulty. Files must follow the naming convention defined in the SourceFolderManager class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceFolderManager():\n",
    "    \"\"\"Manager for the folder which holds the raw .xml data files.\n",
    "    \n",
    "    Args:\n",
    "        src_folder: Path to folder which holds .xml files. \n",
    "        tgt_folder: Path to folder where to save the reorganized files.\n",
    "    \n",
    "    Files inside `src_folder` must be organized by song, such that all \n",
    "        files for a song are in one folder. No two songs can be in the\n",
    "        same folder.\n",
    "    Files must follow the naming convention:\n",
    "        [Song Name]_[Performance Level]-[Song Part]-[Hand].xml, where:\n",
    "            Performance Level is one of ['_beg', '_int', '_adv']\n",
    "            Hand is one of ['lh', 'rh', 'bh']\n",
    "            Song Part must be a unique string given a song and a \n",
    "                performance level. Additionally, Song Part must have 1:1\n",
    "                correspondence across the Performance Levels of a song.\n",
    "    Folders can be nested and do NOT need to follow a naming convention.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, src_folder, tgt_folder=None):\n",
    "        self.src_folder = src_folder\n",
    "        self.tgt_folder = tgt_folder\n",
    "        self.files_index = self._build_index()\n",
    "        \n",
    "    def _build_index(self):\n",
    "        \"\"\" Builds DataFrame which indexes and classifies the files in `src_folder`\"\"\"\n",
    "        \n",
    "        files_index = dict()\n",
    "        \n",
    "        for path, directories, files in os.walk(self.src_folder):\n",
    "            for file in files:\n",
    "                file_match = re.match(r'^[A-Za-z0-9]+(_)(adv|int|beg)-[a-z0-9]+-(lh|rh|bh).xml$', file)\n",
    "                if file_match:\n",
    "                    file_id = file\n",
    "                    name = re.match(r'^[A-Za-z0-9]+(?=(_))', file).group(0)\n",
    "                    level = re.search(r'(?<=_)(adv|int|beg)(?=(-))', file).group(0)\n",
    "                    part = re.search(r'(?<=_(adv|int|beg)-)[A-Za-z0-9]+(?=(-))', file).group(0)\n",
    "                    hand = re.search(r'(?<=-)(lh|rh|bh)(?=(.xml))', file).group(0)\n",
    "                    \n",
    "                    files_index[file_id] = {\n",
    "                        \"name\" : name,\n",
    "                        \"level\" : level,\n",
    "                        \"part\" : part,\n",
    "                        \"hand\" : hand,\n",
    "                        \"path\" : os.path.join(path, file)\n",
    "                    }\n",
    "                    \n",
    "        return pd.DataFrame.from_dict(files_index, orient='index').sort_values(by=['part'])\n",
    "        \n",
    "    \n",
    "    def collate(self, hand = 'bh',\n",
    "                level = [('int', 'adv'), ('beg', 'adv'), ('beg', 'int')]):\n",
    "        \"\"\"Collates source -> target .xml pairs from files in a data folder. \n",
    "            \n",
    "            Args:\n",
    "                hand: One of `lh`, `rh`, `bh`.\n",
    "                level: A list of tuples, where the first element is the desired\n",
    "                source level of playing difficulty, and the second element is the target\n",
    "            Returns:\n",
    "                A list of (`src`, `tgt`) tuples with paths to .xml files. Both paths point\n",
    "                to .xml files of the same song, part and hand but varying difficulty.\n",
    "                \n",
    "            Asserts validity of arguments.\n",
    "            \n",
    "        \"\"\"\n",
    "       \n",
    "        assert set(sum(level, ())).issubset(('int', 'adv', 'beg'))\n",
    "        assert hand in ['lf', 'rh', 'bh']\n",
    "        \n",
    "        collated = list()\n",
    "        \n",
    "        # Iterate over all songs\n",
    "        for song_name in self.files_index['name'].unique():\n",
    "            \n",
    "            # Temp dataframe sliced by the current song and hand\n",
    "            _song_df = self.files_index.loc[(self.files_index['name'] == song_name) & \n",
    "                                            (self.files_index['hand'] == hand)]\n",
    "            # Get available levels for a song\n",
    "            available_levels = _song_df['level'].unique()\n",
    "            \n",
    "            # Check which requested pairings are possible\n",
    "            for pairing in level:\n",
    "                if pairing[0] and pairing[1] in available_levels:\n",
    "                    \n",
    "                    src = _song_df.loc[_song_df['level'] == pairing[0]]['part']\n",
    "                    tgt = _song_df.loc[_song_df['level'] == pairing[1]]['part']\n",
    "                    \n",
    "                    try:\n",
    "                        # Two levels of difficulty must have matching parts\n",
    "                        assert list(src) == list(tgt)\n",
    "                        src = _song_df.loc[_song_df['level'] == pairing[0]]['path']\n",
    "                        tgt = _song_df.loc[_song_df['level'] == pairing[1]]['path']\n",
    "                        collated += list(zip(src, tgt))\n",
    "                    except:\n",
    "                        print('INFO: Skipping \"{}\" because of mismatching parts.'.format(song_name))\n",
    "        \n",
    "        return collated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_instance = SourceFolderManager(constants.SRC_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Skipping \"iwontgiveup\" because of mismatching parts.\n",
      "INFO: Skipping \"YouveGotAFriendInMe\" because of mismatching parts.\n",
      "INFO: Skipping \"YouveGotAFriendInMe\" because of mismatching parts.\n",
      "INFO: Skipping \"hero\" because of mismatching parts.\n",
      "INFO: Skipping \"everytimeyougoaway\" because of mismatching parts.\n",
      "INFO: Skipping \"canthelpfallinginlove\" because of mismatching parts.\n",
      "INFO: Skipping \"YoureMyBestFriend\" because of mismatching parts.\n",
      "INFO: Skipping \"YoureMyBestFriend\" because of mismatching parts.\n",
      "INFO: Skipping \"dontyouforgetaboutme\" because of mismatching parts.\n",
      "INFO: Skipping \"Angie\" because of mismatching parts.\n",
      "INFO: Skipping \"Angie\" because of mismatching parts.\n",
      "INFO: Skipping \"sevenyears\" because of mismatching parts.\n",
      "INFO: Skipping \"sevenyears\" because of mismatching parts.\n"
     ]
    }
   ],
   "source": [
    "collated = manager_instance.collate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collated[10:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manager_instance.files_index.loc[(manager_instance.files_index['name'] == 'iwontgiveup')\n",
    "#                                 & (manager_instance.files_index['hand'] == 'bh')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load XMLs to TFRecord\n",
    "\n",
    "This will take the `.xml` files from the `INPUT_DIR` and convert them to a single `.tfrecord` file, which is a collection of `NoteSequence` protos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converting files in './'.\n",
      "WARNING:tensorflow:Unable to find a converter for file ./.DS_Store\n",
      "WARNING:tensorflow:Unable to find a converter for file ./Ben_demographics.csv\n",
      "WARNING:tensorflow:Unable to find a converter for file ./TF Playground.ipynb\n",
      "WARNING:tensorflow:Unable to find a converter for file ./Ben_all.csv\n",
      "WARNING:tensorflow:Unable to find a converter for file ./PCA Ben.ipynb\n",
      "WARNING:tensorflow:Unable to find a converter for file ./Ben_Likart.csv\n",
      "WARNING:tensorflow:Unable to find a converter for file ./.gitmodules\n",
      "INFO:tensorflow:Converted MusicXML file ./sevenyears_adv-wholeSong-bh.xml.\n",
      "WARNING:tensorflow:Unable to find a converter for file ./README.md\n",
      "WARNING:tensorflow:Unable to find a converter for file ./Pytorch seq2seq_translation_tutorial.ipynb\n",
      "WARNING:tensorflow:Unable to find a converter for file ./Pytorch.ipynb\n",
      "WARNING:tensorflow:Unable to find a converter for file ./Survey data.csv\n",
      "WARNING:tensorflow:Unable to find a converter for file ./.ipynb_checkpoints\n",
      "WARNING:tensorflow:Unable to find a converter for file ./.git\n",
      "INFO:tensorflow:Converted MusicXML file ./sevenyears_adv-intro-bh.xml.\n",
      "WARNING:tensorflow:Unable to find a converter for file ./data\n",
      "WARNING:tensorflow:Unable to find a converter for file ./1_data_processing.ipynb\n",
      "WARNING:tensorflow:Unable to find a converter for file ./test.tfrecord\n"
     ]
    }
   ],
   "source": [
    "convert_dir_to_note_sequences.convert_directory(INPUT_DIR, TFRECORD_FILE, recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Useful scripts for reading TFRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read the contents of the TFRecord file holding NoteSequence records like this:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from magenta.music import note_sequence_io\n",
    "\n",
    "for record in note_sequence_io.note_sequence_record_iterator(TFRECORD_FILE):\n",
    "    note_sequence = record\n",
    "note_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a more general record iterator, which accepts as a second argument the protocol buffer class to be used for deserialization. Yields a generator."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from magenta.protobuf import music_pb2\n",
    "from magenta.pipelines import pipeline\n",
    "\n",
    "for record in pipeline.tf_record_iterator(TFRECORD_FILE, music_pb2.NoteSequence):\n",
    "    note_sequence = record\n",
    "note_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
