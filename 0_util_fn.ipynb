{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## constants\n",
    "\n",
    "Constants for music processing in Magenta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequence_example_lib\n",
    "\n",
    "Utility functions for working with tf.train.SequenceExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.common import sequence_example_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.common import sequence_example_lib"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Returns a SequenceExample for the given inputs and labels.\n",
    "sequence_example_lib.make_sequence_example()\n",
    "\n",
    "# Reads batches of SequenceExamples from TFRecords and pads them.\n",
    "sequence_example_lib.get_padded_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## events_lib\n",
    "\n",
    "Abstract base classes for working with musical event sequences.\n",
    "The abstract `EventSequence` class is an interface for a sequence of musical\n",
    "events. The `SimpleEventSequence` class is a basic implementation of this\n",
    "interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.music import events_lib"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Stores a quantized stream of events.\n",
    "class EventSequence(object)\n",
    "\n",
    "# Base class. Stores a quantized stream of events\n",
    "class SimpleEventSequence(EventSequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model\n",
    "\n",
    "Provides a uniform interface for interacting with any model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.music import model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Abstract class for models\n",
    "# Implements default session checkpoint restore methods.\n",
    "class BaseModel(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note_sequence_io\n",
    "\n",
    "For reading/writing serialized NoteSequence protos to/from TFRecord files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.music import note_sequence_io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notebook_utils\n",
    "\n",
    "Python functions which run only within a Jupyter or Colab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.music import notebook_utils"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Creates an HTML5 audio widget to play a sound in Colab.\n",
    "notebook_utils.colab_play()\n",
    "\n",
    "# Creates an interactive player for a synthesized note sequence.\n",
    "notebook_utils.play_sequence()\n",
    "\n",
    "# Creates an interactive pianoroll for a tensorflow.magenta.NoteSequence.\n",
    "notebook_utils.plot_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder_decoder\n",
    "\n",
    "Classes for converting between event sequences and models inputs/outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.music import encoder_decoder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# An interface for specifying a one-hot encoding of individual events\n",
    "class OneHotEncoding(object)\n",
    "\n",
    "# An abstract class for translating between events and model data\n",
    "class EventSequenceEncoderDecoder(object)\n",
    "\n",
    "# An EventSequenceEncoderDecoder that produces a one-hot encoding.\n",
    "class OneHotEventSequenceEncoderDecoder(EventSequenceEncoderDecoder)\n",
    "\n",
    "# An EventSequenceEncoderDecoder that encodes repeated events and meter\n",
    "class LookbackEventSequenceEncoderDecoder(EventSequenceEncoderDecoder)\n",
    "\n",
    "# An encoder/decoder for conditional event sequences\n",
    "class ConditionalEventSequenceEncoderDecoder(object)\n",
    "\n",
    "# An encoder that augments a base encoder with a disable flag.\n",
    "class OptionalEventSequenceEncoder(EventSequenceEncoderDecoder)\n",
    "\n",
    "# An encoder that concatenates multiple component encoders\n",
    "class MultipleEventSequenceEncoder(EventSequenceEncoderDecoder)\n",
    "\n",
    "# A pipeline that converts an EventSequence to a model encoding\n",
    "class EncoderPipeline(pipeline.Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance_encoder_decoder\n",
    "\n",
    "Classes for converting between performance input and model input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.music import performance_encoder_decoder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Modulo encoding for performance events.\n",
    "class PerformanceModuloEncoding(object)\n",
    "\n",
    "# An EventSequenceEncoderDecoder for modulo encoding performance events\n",
    "class ModuloPerformanceEventSequenceEncoderDecoder(EventSequenceEncoderDecoder)\n",
    "\n",
    "# One-hot encoding for performance events\n",
    "class PerformanceOneHotEncoding(encoder_decoder.OneHotEncoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance_controls\n",
    "\n",
    "Classes for computing performance control signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.music import performance_controls"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Control signal used for conditional generation of performances\n",
    "class PerformanceControlSignal(object)\n",
    "\n",
    "# Note density (notes per second) performance control signal\n",
    "class NoteDensityPerformanceControlSignal(PerformanceControlSignal)\n",
    "\n",
    "# Pitch class histogram performance control signal\n",
    "class PitchHistogramPerformanceControlSignal(PerformanceControlSignal)\n",
    "\n",
    "all_performance_control_signals = [\n",
    "    NoteDensityPerformanceControlSignal,\n",
    "    PitchHistogramPerformanceControlSignal ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance_lib\n",
    "\n",
    "Utility functions for working with polyphonic performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.music import performance_lib"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Class for storing events in a performance\n",
    "PerformanceEvent(object)\n",
    "\n",
    "# Stores a polyphonic sequence as a stream of performance events\n",
    "# Events are PerformanceEvent objects that encode event type and value.\n",
    "BasePerformance(events_lib.EventSequence)\n",
    "\n",
    "# Performance with absolute timing and unknown meter\n",
    "Performance(BasePerformance)\n",
    "\n",
    "# Performance with quarter-note relative timing\n",
    "MetricPerformance(BasePerformance)\n",
    "\n",
    "# Extracts one or more performances from the given quantized NoteSequence\n",
    "performance_lib.extract_performances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
