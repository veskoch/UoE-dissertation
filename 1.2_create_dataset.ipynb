{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "\n",
    "This will run data through a few pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import magenta\n",
    "\n",
    "from magenta.pipelines import pipeline\n",
    "from magenta.protobuf import music_pb2\n",
    "from magenta.protobuf import generator_pb2\n",
    "from magenta.pipelines import pipeline\n",
    "from magenta.pipelines import pipelines_common\n",
    "from magenta.pipelines import dag_pipeline\n",
    "from magenta.pipelines import note_sequence_pipelines\n",
    "\n",
    "import arrangement_create_dataset\n",
    "import arrangement_model\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POINTERS**\n",
    "* `perf_extractor` converts a `NoteSequence` of MIDI-like sequence events (`NOTE ON`, `NOTE OFF`) to a `music.Performance` additionally encoding TIME SHIFT events.\n",
    "* `encoder_pipeline` takes a list-like sequence of events and returns a `tf.train.SequenceExample` containing inputs and labels.\n",
    "    * **TO-DO**: Write a new class like `OneHotEventSequenceEncoderDecoder` (important methods: `events_to_input` and `events_to_label`), need to overwrite the inherited `encode`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderPipeline(pipeline.Pipeline):\n",
    "    \"\"\"A Pipeline that converts performances to a model specific encoding.\"\"\"\n",
    "\n",
    "    def __init__(self, config, name):\n",
    "        \"\"\"Constructs an EncoderPipeline.\n",
    "\n",
    "        Args:\n",
    "          config: A PerformanceRnnConfig that specifies the encoder/decoder and\n",
    "              note density conditioning behavior.\n",
    "          name: A unique pipeline name.\n",
    "        \"\"\"\n",
    "        super(EncoderPipeline, self).__init__(\n",
    "            input_type=magenta.music.Performance,\n",
    "            output_type=tf.train.SequenceExample,\n",
    "            name=name)\n",
    "        self._encoder_decoder = config.encoder_decoder\n",
    "        self._control_signals = config.control_signals\n",
    "        self._optional_conditioning = config.optional_conditioning\n",
    "\n",
    "    def transform(self, performance):\n",
    "        if self._control_signals:\n",
    "            # Encode conditional on control signals.\n",
    "            control_sequences = []\n",
    "            for control in self._control_signals:\n",
    "                control_sequences.append(control.extract(performance))\n",
    "            control_sequence = zip(*control_sequences)\n",
    "            if self._optional_conditioning:\n",
    "                # Create two copies, one with and one without conditioning.\n",
    "                encoded = [\n",
    "                    self._encoder_decoder.encode(\n",
    "                        zip([disable] * len(control_sequence), control_sequence),\n",
    "                        performance)\n",
    "                    for disable in [False, True]]\n",
    "            else:\n",
    "                encoded = [self._encoder_decoder.encode(\n",
    "                    control_sequence, performance)]\n",
    "        else:\n",
    "            # Encode unconditional.\n",
    "            encoded = [self._encoder_decoder.encode(performance)]\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceExtractor(pipeline.Pipeline):\n",
    "    \"\"\"Extracts polyphonic tracks from a quantized NoteSequence.\"\"\"\n",
    "\n",
    "    def __init__(self, num_velocity_bins, name=None):\n",
    "        super(PerformanceExtractor, self).__init__(\n",
    "            input_type=music_pb2.NoteSequence,\n",
    "            output_type=magenta.music.Performance,\n",
    "            name=name)\n",
    "        self._num_velocity_bins = num_velocity_bins\n",
    "\n",
    "    def transform(self, quantized_sequence):\n",
    "        performances, stats = magenta.music.extract_performances(\n",
    "            quantized_sequence,\n",
    "            num_velocity_bins=self._num_velocity_bins)\n",
    "        self._set_stats(stats)\n",
    "        return performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline_graph(config, \n",
    "                         eval_ratio, \n",
    "                         test_ratio,\n",
    "                         collection_name):\n",
    "    \"\"\"Returns the Pipeline instance which creates the RNN dataset.\n",
    "\n",
    "    Args:\n",
    "        config: A PerformanceRnnConfig.\n",
    "        eval_ratio: Fraction of input to set aside for evaluation set.\n",
    "        test_ratio: Fraction of input to set aside for test set.\n",
    "\n",
    "    Returns:\n",
    "        A pipeline.Pipeline instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Stretch by -5%, -2.5%, 0%, 2.5%, and 5%.\n",
    "    stretch_factors = [0.95, 0.975, 1.0, 1.025, 1.05]\n",
    "\n",
    "    # Transpose no more than a major third.\n",
    "    transposition_range = range(-3, 4)\n",
    "\n",
    "    partitioner = pipelines_common.RandomPartition(\n",
    "        music_pb2.NoteSequence,\n",
    "        ['eval_arrangement' + '_' + collection_name, \n",
    "         'test_arrangement' + '_' + collection_name, \n",
    "         'train_arrangement' + '_' + collection_name],\n",
    "        [eval_ratio, test_ratio])\n",
    "    dag = {partitioner: dag_pipeline.DagInput(music_pb2.NoteSequence)}\n",
    "\n",
    "    for mode in ['eval', 'test', 'train']:\n",
    "        key = mode + '_arrangement' + '_' + collection_name\n",
    "        \n",
    "        sustain_pipeline = note_sequence_pipelines.SustainPipeline(\n",
    "            name='SustainPipeline_' + key)\n",
    "        \n",
    "        stretch_pipeline = note_sequence_pipelines.StretchPipeline(\n",
    "            stretch_factors if mode == 'train' else [1.0],\n",
    "            name='StretchPipeline_' + key)\n",
    "        \n",
    "        splitter = note_sequence_pipelines.Splitter(\n",
    "            hop_size_seconds=30.0, name='Splitter_' + key)\n",
    "        \n",
    "        quantizer = note_sequence_pipelines.Quantizer(\n",
    "            steps_per_second=config.steps_per_second, name='Quantizer_' + key)\n",
    "        \n",
    "        transposition_pipeline = note_sequence_pipelines.TranspositionPipeline(\n",
    "            transposition_range if mode == 'train' else [0],\n",
    "            name='TranspositionPipeline_' + key)\n",
    "        \n",
    "        perf_extractor = PerformanceExtractor(\n",
    "            num_velocity_bins=config.num_velocity_bins,\n",
    "            name='PerformanceExtractor_' + key)\n",
    "            # input_type = music_pb2.NoteSequence\n",
    "            # output_type = magenta.music.Performance\n",
    "        \n",
    "        encoder_pipeline = EncoderPipeline(\n",
    "            config, name='EncoderPipeline_' + key)\n",
    "            # input_type = magenta.music.Performance\n",
    "            # output_type = tf.train.SequenceExample\n",
    "    \n",
    "        # Partition > Quantize > Extract Performance > Encode > Out\n",
    "        dag[quantizer] = partitioner[key]\n",
    "        dag[perf_extractor] = quantizer\n",
    "        dag[encoder_pipeline] = perf_extractor\n",
    "        dag[dag_pipeline.DagOutput(key)] = encoder_pipeline\n",
    "\n",
    "    return dag_pipeline.DAGPipeline(dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    for collection_name in ['inputs', 'targets']:\n",
    "        \n",
    "        src_file = os.path.join(constants.COLLATED_NOTE_SEQ_DIR, \n",
    "                                   collection_name + '.tfrecord')\n",
    "        output_dir = os.path.join(constants.ENCODED_SEQ_EXMPL_DIR)\n",
    "        \n",
    "        # Construct the pipeline graph\n",
    "        pipeline_graph = build_pipeline_graph(\n",
    "            eval_ratio = constants.EVAL_RATIO,\n",
    "            test_ratio = constants.TEST_RATIO,\n",
    "            collection_name = collection_name,\n",
    "            config = constants.default_configs[constants.CONFIG])\n",
    "\n",
    "        # Runs pipeline graph on a data source and writes output to dir\n",
    "        pipeline.run_pipeline_serial(\n",
    "            pipeline_graph,\n",
    "            pipeline.tf_record_iterator(src_file, \n",
    "                                        pipeline_graph.input_type),\n",
    "            output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults to 0, all logs are shown. \n",
    "# 1 to filter out INFO logs\n",
    "# 2 to additionall filter out WARNING\n",
    "# 3 to additionally filter out ERROR\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 76 inputs total. Produced 76 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_inputs_performance_lengths_in_seconds:\n",
      "  [10,20): 2\n",
      "  [30,40): 2\n",
      "  [60,120): 2\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_inputs_performance_lengths_in_seconds:\n",
      "  [10,20): 1\n",
      "  [20,30): 1\n",
      "  [30,40): 5\n",
      "  [60,120): 2\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_inputs_performance_lengths_in_seconds:\n",
      "  [10,20): 11\n",
      "  [20,30): 7\n",
      "  [30,40): 25\n",
      "  [40,60): 12\n",
      "  [60,120): 6\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_eval_arrangement_inputs_count: 6\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_test_arrangement_inputs_count: 9\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_train_arrangement_inputs_count: 61\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 76 inputs total. Produced 76 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_targets_performance_lengths_in_seconds:\n",
      "  [10,20): 9\n",
      "  [20,30): 1\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_targets_performance_lengths_in_seconds:\n",
      "  [10,20): 6\n",
      "  [20,30): 1\n",
      "  [30,40): 1\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_targets_performance_lengths_in_seconds:\n",
      "  [10,20): 33\n",
      "  [20,30): 11\n",
      "  [30,40): 8\n",
      "  [40,60): 6\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_eval_arrangement_targets_count: 10\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_test_arrangement_targets_count: 8\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_train_arrangement_targets_count: 58\n"
     ]
    }
   ],
   "source": [
    "create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful IO\n",
    "\n",
    "##### Read `.tfrecord` of NoteSequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = './data/note_seqs/inputs.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = list()\n",
    "for record in pipeline.tf_record_iterator(tfrecord_path, music_pb2.NoteSequence):\n",
    "    records.append(record)\n",
    "\n",
    "# Hint: To look at first record, run `records[0]`\n",
    "# Hint 2: This is useful to drill inside: records[0].feature_lists.feature_list['inputs'].feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiate pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.models.performance_rnn import performance_model\n",
    "from magenta.pipelines import note_sequence_pipelines\n",
    "\n",
    "config = constants.default_configs['performance']\n",
    "\n",
    "quantizer_instance = note_sequence_pipelines.Quantizer(steps_per_second = config.steps_per_second,\n",
    "                                                       name='Quantizer_jupyter')\n",
    "perf_extractor_instance = PerformanceExtractor(num_velocity_bins = config.num_velocity_bins)\n",
    "encoder_pipeline_instance = EncoderPipeline(config,\n",
    "                                            name='EncoderPipeline_jupyter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-through pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in pipeline.tf_record_iterator(tfrecord_path, music_pb2.NoteSequence):\n",
    "    note_sequence1 = record\n",
    "# note_sequence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence2 = quantizer_instance.transform(note_sequence1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 58),\n",
       " PerformanceEvent(1, 62),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 75),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 58),\n",
       " PerformanceEvent(2, 62),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(3, 50),\n",
       " PerformanceEvent(1, 76),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 76),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 62),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 75),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 62),\n",
       " PerformanceEvent(1, 52),\n",
       " PerformanceEvent(1, 55),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(2, 52),\n",
       " PerformanceEvent(2, 55),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(1, 52),\n",
       " PerformanceEvent(1, 55),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(3, 50),\n",
       " PerformanceEvent(1, 76),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 76),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 52),\n",
       " PerformanceEvent(2, 55),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 58),\n",
       " PerformanceEvent(1, 62),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 75),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 58),\n",
       " PerformanceEvent(2, 62),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(1, 72),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(2, 72),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(1, 72),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 72),\n",
       " PerformanceEvent(1, 72),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 72),\n",
       " PerformanceEvent(1, 72),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 72),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 62),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(1, 76),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 76),\n",
       " PerformanceEvent(1, 74),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 62),\n",
       " PerformanceEvent(2, 74),\n",
       " PerformanceEvent(1, 52),\n",
       " PerformanceEvent(1, 55),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(1, 76),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 52),\n",
       " PerformanceEvent(2, 55),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(2, 76),\n",
       " PerformanceEvent(1, 52),\n",
       " PerformanceEvent(1, 55),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(1, 76),\n",
       " PerformanceEvent(3, 50),\n",
       " PerformanceEvent(2, 76),\n",
       " PerformanceEvent(1, 76),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 76),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 52),\n",
       " PerformanceEvent(2, 55),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 58),\n",
       " PerformanceEvent(1, 62),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 75),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 58),\n",
       " PerformanceEvent(2, 62),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(3, 50),\n",
       " PerformanceEvent(1, 81),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 81),\n",
       " PerformanceEvent(1, 79),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(2, 79),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 62),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 75),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 62),\n",
       " PerformanceEvent(1, 52),\n",
       " PerformanceEvent(1, 55),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(2, 52),\n",
       " PerformanceEvent(2, 55),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(1, 52),\n",
       " PerformanceEvent(1, 55),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(3, 50),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(1, 81),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 52),\n",
       " PerformanceEvent(2, 55),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(2, 81),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 58),\n",
       " PerformanceEvent(1, 62),\n",
       " PerformanceEvent(1, 79),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 79),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 50),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 58),\n",
       " PerformanceEvent(2, 62),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(1, 72),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 72),\n",
       " PerformanceEvent(1, 72),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 72),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(1, 53),\n",
       " PerformanceEvent(1, 57),\n",
       " PerformanceEvent(1, 62),\n",
       " PerformanceEvent(1, 77),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 77),\n",
       " PerformanceEvent(1, 76),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 76),\n",
       " PerformanceEvent(1, 74),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 53),\n",
       " PerformanceEvent(2, 57),\n",
       " PerformanceEvent(2, 62),\n",
       " PerformanceEvent(2, 74),\n",
       " PerformanceEvent(1, 52),\n",
       " PerformanceEvent(1, 55),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(1, 76),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 52),\n",
       " PerformanceEvent(2, 55),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(2, 76),\n",
       " PerformanceEvent(1, 52),\n",
       " PerformanceEvent(1, 55),\n",
       " PerformanceEvent(1, 60),\n",
       " PerformanceEvent(1, 76),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 76),\n",
       " PerformanceEvent(1, 72),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 72),\n",
       " PerformanceEvent(1, 74),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 74),\n",
       " PerformanceEvent(1, 76),\n",
       " PerformanceEvent(3, 25),\n",
       " PerformanceEvent(2, 52),\n",
       " PerformanceEvent(2, 55),\n",
       " PerformanceEvent(2, 60),\n",
       " PerformanceEvent(2, 76)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_sequence3 = perf_extractor_instance.transform(note_sequence2)[0]\n",
    "\n",
    "# note_sequence3.to_sequence()        # converts Performance to NoteSequence proto\n",
    "# note_sequence3.__getitem__(4)       # return event at position\n",
    "# note_sequence3.steps_per_second     # if Performance(BasePerformance)\n",
    "# note_sequence3.steps_per_quarter    # if MetricPerformance(BasePerformance)\n",
    "note_sequence3._events              # list of all events\n",
    "# len(note_sequence3._events)         # len of events\n",
    "# note_sequence3.num_steps            # len of sequence in quantized steps\n",
    "# note_sequence3.steps                # list of the time step at each event in the sequence\n",
    "\n",
    "# returns an iterator\n",
    "# for i, event in enumerate(note_sequence3.__iter__()): \n",
    "#     print(event)\n",
    "#     if i > 25:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence4 = encoder_pipeline_instance.transform(note_sequence3)[0]\n",
    "# note_sequence4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining which position is 1 in the one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_event_ranges = [\n",
    "    (1, 1, 127),\n",
    "    (2, 1, 127),\n",
    "    (3, 1, 100)\n",
    "]\n",
    "\n",
    "def encode_event(event):\n",
    "    offset = 0\n",
    "    for event_type, min_value, max_value in _event_ranges:\n",
    "        if event[0] == event_type:\n",
    "            return offset + event[1] - min_value\n",
    "        offset += max_value - min_value + 1\n",
    "\n",
    "encode_event((3, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate time-shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
