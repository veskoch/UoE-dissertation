# ### ### ### ### 
# Update for every model

# Custom model configuration file
model: r_arb_2_model.py

# List of configuration files.
# Accepts multiples so that some parts can be made reusable.
config: [r_arb_2_hyperparams.yml]

# Checkpoint or directory to use for inference or export 
# when a directory is set, the latest checkpoint is used
checkpoint_path: run_dir/r_arb_2/


# ### ### ### ### 
# Other

# One of "train_and_eval", "train_and_eval_2", "train", "eval", "infer", "export", "score".
run: train_and_eval_2

# Logs some prediction time metrics.
log_prediction_time: true

# If set, model_dir will be created relative to this location.
run_dir: run_dir


# ### ### ### ### 
# No need to modify those

# Number of GPUs to use for in-graph replication.
num_gpus: 1

# hostname:port of the chief worker (for distributed training).
chief_host:

# Comma-separated list of hostname:port of workers
# for distributed training)."
worker_hosts: 

# Comma-separated list of hostname:port of parameter servers
# (for distributed training).
ps_hosts:

# Type of the task to run (for distributed training).
# One of "chief", "worker", "ps", "evaluator"
task_type: chief

# ID of the task (for distributed training).
task_index: 0

# One of "DEBUG", "ERROR", "FATAL", "INFO", "WARN"
log_level: INFO

# Random seed.
seed: null

# Allocate GPU memory dynamically.
gpu_allow_growth: false

# Number of intra op threads (0 means the system picks
# an appropriate number).
intra_op_parallelism_threads: 0

# Number of inter op threads (0 means the system picks
# an appropriate number).
inter_op_parallelism_threads: 0


# ### ### ### ### 
# Inactive

# Model type from the catalog.
model_type: 

# Run inference on this file.
features_file:

# File used to save predictions. If not set, predictions are printed
# on the standard output.
predictions_file:

# If set, data files are expected to be relative to this location.
data_dir: 