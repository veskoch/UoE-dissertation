{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good tutorial on building TFRecord files\n",
    "\n",
    "\n",
    "https://medium.com/@WuStangDan/step-by-step-tensorflow-object-detection-api-tutorial-part-2-converting-dataset-to-tfrecord-47f24be9248d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful scripts for reading TFRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read the contents of the TFRecord file holding NoteSequence records like this:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from magenta.music import note_sequence_io\n",
    "\n",
    "for record in note_sequence_io.note_sequence_record_iterator(TFRECORD_FILE):\n",
    "    note_sequence = record\n",
    "note_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a more general record iterator, which accepts as a second argument the protocol buffer class to be used for deserialization. Yields a generator.\n",
    "\n",
    "Frequently used protos classes include:\n",
    "    * `tf.train.SequenceExample`\n",
    "    * `music_pb2.NoteSequence`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from magenta.protobuf import music_pb2\n",
    "from magenta.pipelines import pipeline\n",
    "\n",
    "for record in pipeline.tf_record_iterator(TFRECORD_FILE, music_pb2.NoteSequence):\n",
    "    note_sequence = record\n",
    "note_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful IO for debugging Pipelines [`1.2 Preprocess.ipynb`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load a `.tfrecord` of NoteSequences.\n",
    "tfrecord_path = './data/note_seqs/inputs.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = list()\n",
    "for record in pipeline.tf_record_iterator(tfrecord_path, music_pb2.NoteSequence):\n",
    "    records.append(record)\n",
    "\n",
    "# Hint: To look at first record, run `records[0]`\n",
    "# Hint 2: This is useful to drill inside: records[0].feature_lists.feature_list['inputs'].feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiate pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.models.performance_rnn import performance_model\n",
    "from magenta.pipelines import note_sequence_pipelines\n",
    "\n",
    "config = constants.default_configs['performance']\n",
    "\n",
    "quantizer_instance = note_sequence_pipelines.Quantizer(steps_per_second = config.steps_per_second,\n",
    "                                                       name='Quantizer_jupyter')\n",
    "perf_extractor_instance = PerformanceExtractor(num_velocity_bins = config.num_velocity_bins)\n",
    "encoder_pipeline_instance = EncoderPipeline(config,\n",
    "                                            name='EncoderPipeline_jupyter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-through pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in pipeline.tf_record_iterator(tfrecord_path, music_pb2.NoteSequence):\n",
    "    note_sequence1 = record\n",
    "# note_sequence1.SerializeToString()\n",
    "# note_sequence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence2 = quantizer_instance.transform(note_sequence1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence3 = perf_extractor_instance.transform(note_sequence2)[0]\n",
    "\n",
    "# note_sequence3.to_sequence()        # converts Performance to NoteSequence proto\n",
    "# note_sequence3.__getitem__(4)       # return event at position\n",
    "# note_sequence3.steps_per_second     # if Performance(BasePerformance)\n",
    "# note_sequence3.steps_per_quarter    # if MetricPerformance(BasePerformance)\n",
    "# note_sequence3._events              # list of all events\n",
    "# len(note_sequence3._events)         # len of events\n",
    "# note_sequence3.num_steps            # len of sequence in quantized steps\n",
    "# note_sequence3.steps                # list of the time step at each event in the sequence\n",
    "\n",
    "# returns an iterator\n",
    "# for i, event in enumerate(note_sequence3.__iter__()): \n",
    "#     print(event)\n",
    "#     if i > 25:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence4 = encoder_pipeline_instance.transform(note_sequence3)[0]\n",
    "# note_sequence4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
