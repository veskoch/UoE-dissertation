{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq tut1\n",
    "\n",
    "\n",
    "https://github.com/ematvey/tensorflow-seq2seq-tutorials/blob/master/1-seq2seq.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(inputs, max_sequence_length=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs:\n",
    "            list of sentences (integer lists)\n",
    "        max_sequence_length:\n",
    "            integer specifying how large should `max_time` dimension be.\n",
    "            If None, maximum sequence length would be used\n",
    "    \n",
    "    Outputs:\n",
    "        inputs_time_major:\n",
    "            input sentences transformed into time-major matrix \n",
    "            (shape [max_time, batch_size]) padded with 0s\n",
    "        sequence_lengths:\n",
    "            batch-sized list of integers specifying amount of active \n",
    "            time steps in each input sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    sequence_lengths = [len(seq) for seq in inputs]\n",
    "    batch_size = len(inputs)\n",
    "    \n",
    "    if max_sequence_length is None:\n",
    "        max_sequence_length = max(sequence_lengths)\n",
    "    \n",
    "    inputs_batch_major = np.zeros(shape=[batch_size, max_sequence_length], dtype=np.int32) # == PAD\n",
    "    \n",
    "    for i, seq in enumerate(inputs):\n",
    "        for j, element in enumerate(seq):\n",
    "            inputs_batch_major[i, j] = element\n",
    "\n",
    "    # [batch_size, max_time] -> [max_time, batch_size]\n",
    "    inputs_time_major = inputs_batch_major.swapaxes(0, 1)\n",
    "\n",
    "    return inputs_time_major, sequence_lengths\n",
    "\n",
    "\n",
    "def random_sequences(length_from, length_to,\n",
    "                     vocab_lower, vocab_upper,\n",
    "                     batch_size):\n",
    "    \"\"\" Generates batches of random integer sequences,\n",
    "        sequence length in [length_from, length_to],\n",
    "        vocabulary in [vocab_lower, vocab_upper]\n",
    "    \"\"\"\n",
    "    if length_from > length_to:\n",
    "            raise ValueError('length_from > length_to')\n",
    "\n",
    "    def random_length():\n",
    "        if length_from == length_to:\n",
    "            return length_from\n",
    "        return np.random.randint(length_from, length_to + 1)\n",
    "    \n",
    "    while True:\n",
    "        yield [\n",
    "            np.random.randint(low=vocab_lower,\n",
    "                              high=vocab_upper,\n",
    "                              size=random_length()).tolist()\n",
    "            for _ in range(batch_size)\n",
    "        ]\n",
    "        \n",
    "def next_feed():\n",
    "    next_batch = next(batches)\n",
    "    encoder_inputs_, _ = batch(next_batch)\n",
    "    decoder_targets_, _ = batch(\n",
    "        [(sequence) + [EOS] for sequence in next_batch]\n",
    "    )\n",
    "    decoder_inputs_, _ = batch(\n",
    "        [[EOS] + (sequence) for sequence in next_batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[5, 7, 8], [6, 3], [3], [1]]\n",
    "xt, xlen = batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape [encoder_max_time, batch_size]\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "\n",
    "# shape [encoder_max_time, batch_size]\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "\n",
    "# shape [decoder_max_time, batch_size]\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random embeddings matrix\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_inputs_embedded,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "del encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder_final_state.h -- activations of the hidden layer\n",
    "# encoder_final_state.c -- output\n",
    "\n",
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, decoder_inputs_embedded,\n",
    "\n",
    "    initial_state=encoder_final_state,\n",
    "\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static : vocab_size\n",
    "# Dynamic : max_time, batch_size\n",
    "\n",
    "# shape [max_time, batch_size, hidden_units] \n",
    "decoder_outputs\n",
    "\n",
    "# shape [max_time, batch_size, vocab_size]\n",
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-05f6ec0fbbf9>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test everything is wired correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_encoded:\n",
      "[[6 3 9]\n",
      " [0 4 8]\n",
      " [0 0 7]]\n",
      "decoder inputs:\n",
      "[[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "decoder predictions:\n",
      "[[1 7 7]\n",
      " [1 7 7]\n",
      " [4 9 9]\n",
      " [4 4 9]]\n"
     ]
    }
   ],
   "source": [
    "batch_ = [[6], [3, 4], [9, 8, 7]]\n",
    "\n",
    "batch_, batch_length_ = batch(batch_)\n",
    "print('batch_encoded:\\n' + str(batch_))\n",
    "\n",
    "din_, dlen_ = batch(np.ones(shape=(3, 1), dtype=np.int32),\n",
    "                            max_sequence_length=4)\n",
    "print('decoder inputs:\\n' + str(din_))\n",
    "\n",
    "pred_ = sess.run(decoder_prediction,\n",
    "    feed_dict={\n",
    "        encoder_inputs: batch_,\n",
    "        decoder_inputs: din_,\n",
    "    })\n",
    "print('decoder predictions:\\n' + str(pred_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = random_sequences(length_from=3, length_to=8,\n",
    "                            vocab_lower=2, vocab_upper=10,\n",
    "                            batch_size=batch_size)\n",
    "\n",
    "# print('head of the batch:')\n",
    "# for seq in next(batches)[:10]:\n",
    "#     print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.10126741975545883\n",
      "  sample 1:\n",
      "    input     > [4 8 6 0 0 0 0 0]\n",
      "    predicted > [4 8 6 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 9 9 0 0 0 0 0]\n",
      "    predicted > [3 9 9 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 3 3 9 9 0 0 0]\n",
      "    predicted > [3 3 9 9 9 1 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.06616536527872086\n",
      "  sample 1:\n",
      "    input     > [9 3 6 3 5 5 0 0]\n",
      "    predicted > [9 3 6 3 5 5 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 8 3 8 5 2 0 0]\n",
      "    predicted > [8 8 3 8 5 2 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 9 5 2 4 6 9 2]\n",
      "    predicted > [8 9 5 2 4 6 9 2 1]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.04467751830816269\n",
      "  sample 1:\n",
      "    input     > [2 6 8 3 3 6 7 0]\n",
      "    predicted > [2 6 8 3 3 6 7 1 0]\n",
      "  sample 2:\n",
      "    input     > [3 5 5 3 0 0 0 0]\n",
      "    predicted > [3 5 5 3 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 3 7 0 0 0 0 0]\n",
      "    predicted > [9 3 7 1 0 0 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.048737652599811554\n",
      "  sample 1:\n",
      "    input     > [3 5 5 0 0 0 0 0]\n",
      "    predicted > [3 5 5 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 7 4 9 4 9 2 7]\n",
      "    predicted > [3 7 4 9 4 9 2 7 1]\n",
      "  sample 3:\n",
      "    input     > [6 2 9 5 6 0 0 0]\n",
      "    predicted > [6 2 9 5 6 1 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch_ in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch_ == 0 or batch_ % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch_))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.1101 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c28df4e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
