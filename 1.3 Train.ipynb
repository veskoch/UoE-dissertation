{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will help you define your seq2seq model and train it. \n",
    "\n",
    "**POINTERS**\n",
    "\n",
    "Configurations for this model are stored in 3 places. In order of hierarchy those are:\n",
    "* **Execution Parameters** Holds highest-level of settings for a particular run. Here we choose, for example, whether to train, evaluate or infer. This file loads configurations from the files below.\n",
    "    * `run_config.yml`\n",
    "* **Models** Defines the classe of the chosen model architecture(s).\n",
    "    * `model.py`\n",
    "* **Model Hyperparameters** Holds hyperparameters (i.e. optimizer, learning rate, beam width) for use on the chosen model architecture. What is interesting is that we can provide a set of different hyperparameters and test them all at once during a single run. See `config` variable inside `run_config.yml`.\n",
    "    * [`model_config.yml`]\n",
    "    \n",
    "    \n",
    "The model is based on Open-NMT-tf: [API Refernce](http://opennmt.net/OpenNMT-tf/package/opennmt.html) | [GitHub](https://github.com/OpenNMT/OpenNMT-tf). Most of the core is untouched. Think of this Jupyter Notebook as a thin wrapper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model\n",
    "\n",
    "Execute cell bellow to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'run_dir/model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': gpu_options {\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c3ef2a2b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 1800 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/message.c:4294)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Number of trainable parameters: 10652946\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into run_dir/model_dir/model.ckpt.\n",
      "INFO:tensorflow:loss = 1351.97, step = 1\n"
     ]
    }
   ],
   "source": [
    "import run\n",
    "run.main('_train_config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
