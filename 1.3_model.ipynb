{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "Uses Open-NMT-tf:\n",
    "\n",
    "* [API refernce](http://opennmt.net/OpenNMT-tf/package/opennmt.html)\n",
    "* [GitHub](https://github.com/OpenNMT/OpenNMT-tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opennmt as onmt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \"\"\" \n",
    "    See https://github.com/OpenNMT/OpenNMT-tf/blob/master/opennmt/models/catalog.py\n",
    "    for examples how to define a model.\n",
    "    \"\"\"\n",
    "    return onmt.models.SequenceToSequence(\n",
    "        source_inputter = onmt.inputters.SequenceRecordInputter(),\n",
    "        target_inputter = onmt.inputters.SequenceRecordInputter(),\n",
    "        \n",
    "        encoder = onmt.encoders.BidirectionalRNNEncoder(\n",
    "            num_layers=4,\n",
    "            num_units=512,\n",
    "            reducer=onmt.layers.ConcatReducer(),\n",
    "            cell_class=tf.contrib.rnn.LSTMCell,\n",
    "            dropout=0.3,\n",
    "            residual_connections=False),\n",
    "        \n",
    "        decoder = onmt.decoders.AttentionalRNNDecoder(\n",
    "            num_layers=4,\n",
    "            num_units=512,\n",
    "            bridge=onmt.layers.CopyBridge(),\n",
    "            attention_mechanism_class=tf.contrib.seq2seq.LuongAttention,\n",
    "            cell_class=tf.contrib.rnn.LSTMCell,\n",
    "            dropout=0.3,\n",
    "            residual_connections=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Target inputter must be a WordEmbedder",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a3fc020be42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-f5e376d1ad63>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcell_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             residual_connections=False)\n\u001b[0m\u001b[1;32m     26\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/opennmt/models/sequence_to_sequence.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source_inputter, target_inputter, encoder, decoder, daisy_chain_variables, name)\u001b[0m\n\u001b[1;32m     80\u001b[0m           \"saw: {} and {}\".format(source_inputter.dtype, target_inputter.dtype))\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_inputter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWordEmbedder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target inputter must be a WordEmbedder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     super(SequenceToSequence, self).__init__(\n",
      "\u001b[0;31mTypeError\u001b[0m: Target inputter must be a WordEmbedder"
     ]
    }
   ],
   "source": [
    "model().model_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
