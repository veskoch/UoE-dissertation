{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import magenta\n",
    "\n",
    "from magenta.music import performance_lib\n",
    "\n",
    "from magenta.protobuf import music_pb2\n",
    "\n",
    "from magenta.pipelines import pipeline\n",
    "from magenta.pipelines import pipelines_common\n",
    "from magenta.pipelines import dag_pipeline\n",
    "from magenta.pipelines import note_sequence_pipelines\n",
    "from magenta.pipelines import statistics\n",
    "\n",
    "from magenta.pipelines.pipeline import _guarantee_dict\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults to 0, all logs are shown. \n",
    "# 1 to filter out INFO logs\n",
    "# 2 to additionall filter out WARNING\n",
    "# 3 to additionally filter out ERROR\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "\n",
    "This will run data through a few pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POINTERS**\n",
    "* `perf_extractor` converts a `NoteSequence` of MIDI-like sequence events (`NOTE ON`, `NOTE OFF`) to a `music.Performance` additionally encoding TIME SHIFT events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PIPELINE PARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_config = dict()\n",
    "\n",
    "pipelines_config['data_source_dir'] = \"./data/note_seq_proto/\"\n",
    "pipelines_config['data_target_dir'] = \"./data/performance_seq_text/\"\n",
    "\n",
    "pipelines_config['steps_per_second'] = 100\n",
    "\n",
    "pipelines_config['min_events'] = 1\n",
    "pipelines_config['max_events'] = 10000\n",
    "\n",
    "pipelines_config['eval_ratio'] = 0.1\n",
    "pipelines_config['test_ratio'] = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceExtractor(pipeline.Pipeline):\n",
    "    \"\"\"Extracts polyphonic tracks from a quantized NoteSequence.\"\"\"\n",
    "\n",
    "    def __init__(self, min_events, max_events, num_velocity_bins, name=None):\n",
    "        super(PerformanceExtractor, self).__init__(\n",
    "            input_type=music_pb2.NoteSequence,\n",
    "            output_type=magenta.music.Performance,\n",
    "            name=name)\n",
    "        self._min_events = min_events\n",
    "        self._max_events = max_events\n",
    "        self._num_velocity_bins = num_velocity_bins\n",
    "\n",
    "    def transform(self, quantized_sequence):\n",
    "        performances, stats = magenta.music.extract_performances(\n",
    "            quantized_sequence,\n",
    "            num_velocity_bins=self._num_velocity_bins)\n",
    "        self._set_stats(stats)\n",
    "        return performances\n",
    "    \n",
    "class PerformanceParser(pipeline.Pipeline):\n",
    "    \"\"\"Converts a Performance into a text sequence.\n",
    "    \n",
    "    Individual events become 'words' of A-Z 0-9 separated by space. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name=None):\n",
    "        super(PerformanceParser, self).__init__(\n",
    "            input_type=magenta.music.Performance,\n",
    "            output_type=str,\n",
    "            name=name)\n",
    "        \n",
    "    def transform(self, performance):\n",
    "        strs = []\n",
    "        for event in performance:\n",
    "            if event.event_type == performance_lib.PerformanceEvent.NOTE_ON:\n",
    "                strs.append('ON%s' % event.event_value)\n",
    "            elif event.event_type == performance_lib.PerformanceEvent.NOTE_OFF:\n",
    "                strs.append('OFF%s' % event.event_value)\n",
    "            elif event.event_type == performance_lib.PerformanceEvent.TIME_SHIFT:\n",
    "                strs.append('SHIFT%s' % event.event_value)\n",
    "            else:\n",
    "                raise ValueError('Unknown event type: %s' % event.event_type)\n",
    "        return [' '.join(strs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_text(pipeline,\n",
    "                      input_iterator,\n",
    "                      output_dir):\n",
    "    \"\"\"Runs a pipeline graph saving output to disk as text.\n",
    "     \n",
    "    Run the the pipeline on each input from the iterator one at a time.\n",
    "    A file will be written to `output_dir` for each dataset name specified\n",
    "    by the pipeline. pipeline.transform is called on each input and the\n",
    "    results are aggregated into their correct datasets.\n",
    "\n",
    "    The output type given by `pipeline.output_type` must be str.\n",
    "\n",
    "    Args:\n",
    "        pipeline: A Pipeline instance. `pipeline.output_type` must be a str.\n",
    "        input_iterator: Iterates over the input data. Items returned by it are fed\n",
    "            directly into the pipeline's `transform` method.\n",
    "        output_dir: Path to directory where datasets will be written. Each dataset\n",
    "            is a file whose name contains the pipeline's dataset name. If the\n",
    "            directory does not exist, it will be created.\n",
    "            \n",
    "    Raises:\n",
    "        ValueError: If any of `pipeline`'s output type is not str.\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(pipeline.output_type, dict):\n",
    "        for name, type_ in pipeline.output_type.items():\n",
    "            if type_ != str:\n",
    "                raise ValueError(\n",
    "                    'Pipeline \"%s\" must output %s type. '\n",
    "                    'Output type was %s' % (name, str, type_))\n",
    "    else:\n",
    "         if type_ != str:\n",
    "            raise ValueError(\n",
    "                    'Pipeline \"%s\" must output %s type. '\n",
    "                            'Output type was %s' % (name, str, pipeline.output_type))\n",
    "    \n",
    "    \n",
    "    aggregated_outputs = dict(\n",
    "        [(name, []) for name in pipeline.output_type_as_dict])\n",
    "    total_inputs = 0\n",
    "    total_outputs = 0\n",
    "    stats = []\n",
    "    \n",
    "    output_names = pipeline.output_type_as_dict.keys()\n",
    "    output_paths = [os.path.join(output_dir, name + '.txt')\n",
    "                    for name in output_names]\n",
    "\n",
    "    for path in output_paths:\n",
    "        if os.path.exists(path):\n",
    "            raise FileExistsError('File {} already exists. Please remove and try again.'\n",
    "                                        .format(path))           \n",
    "\n",
    "    writers = dict([(name, open(path, 'a'))\n",
    "                  for name, path in zip(output_names, output_paths)])\n",
    "    \n",
    "    for input_object in input_iterator:\n",
    "        total_inputs += 1\n",
    "        \n",
    "        for name, outputs in _guarantee_dict(\n",
    "            pipeline.transform(input_object),\n",
    "            list(output_names)[0]).items():\n",
    "            \n",
    "            for output in outputs:\n",
    "                writers[name].write(output + '\\n')\n",
    "                \n",
    "            total_outputs += len(outputs)\n",
    "        stats = statistics.merge_statistics(stats + pipeline.get_stats())\n",
    "        if total_inputs % 5000 == 0:\n",
    "            tf.logging.info('Processed %d inputs so far. Produced %d outputs.', \n",
    "                            total_inputs, total_outputs)\n",
    "            statistics.log_statistics_list(stats, tf.logging.info)\n",
    "    tf.logging.info('\\n\\nCompleted.\\n')\n",
    "    tf.logging.info('Processed %d inputs total. Produced %d outputs.',\n",
    "                    total_inputs, total_outputs)\n",
    "    statistics.log_statistics_list(stats, tf.logging.info)\n",
    "    return aggregated_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline_graph(collection_name,\n",
    "                         config):\n",
    "    \"\"\"Returns the Pipeline instance which creates the RNN dataset.\n",
    "\n",
    "    Args:\n",
    "        collection_name:\n",
    "        config: dict() with configuration settings\n",
    "\n",
    "    Returns:\n",
    "        A pipeline.Pipeline instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Stretch by -5%, -2.5%, 0%, 2.5%, and 5%.\n",
    "    stretch_factors = [0.95, 0.975, 1.0, 1.025, 1.05]\n",
    "\n",
    "    # Transpose no more than a major third.\n",
    "    transposition_range = range(-3, 4)\n",
    "\n",
    "    partitioner = pipelines_common.RandomPartition(\n",
    "        music_pb2.NoteSequence,\n",
    "        ['eval_arrangement' + '_' + collection_name, \n",
    "         'test_arrangement' + '_' + collection_name, \n",
    "         'train_arrangement' + '_' + collection_name],\n",
    "        [pipelines_config['eval_ratio'], pipelines_config['test_ratio']])\n",
    "    dag = {partitioner: dag_pipeline.DagInput(music_pb2.NoteSequence)}\n",
    "\n",
    "    for mode in ['eval', 'test', 'train']:\n",
    "        key = mode + '_arrangement' + '_' + collection_name\n",
    "        \n",
    "        quantizer = note_sequence_pipelines.Quantizer(\n",
    "            steps_per_second=pipelines_config['steps_per_second'], \n",
    "            name='Quantizer_' + key)\n",
    "        \n",
    "        perf_extractor = PerformanceExtractor(\n",
    "            min_events=pipelines_config['min_events'],\n",
    "            max_events=pipelines_config['max_events'],\n",
    "            num_velocity_bins=0,\n",
    "            name='PerformanceExtractor_' + key)\n",
    "            # input_type = music_pb2.NoteSequence\n",
    "            # output_type = magenta.music.Performance\n",
    "            \n",
    "        perf_parser = PerformanceParser(\n",
    "            name='PerformanceParser_' + key)\n",
    "            # input_type = magenta.music.Performance\n",
    "            # output_type = str\n",
    "        \n",
    "        dag[quantizer] = partitioner[key]\n",
    "        dag[perf_extractor] = quantizer\n",
    "        dag[perf_parser] = perf_extractor\n",
    "        dag[dag_pipeline.DagOutput(key)] = perf_parser\n",
    "        \n",
    "    return dag_pipeline.DAGPipeline(dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    for collection_name in ['inputs', 'targets']:\n",
    "        \n",
    "        src_file = os.path.join(pipelines_config['data_source_dir'], \n",
    "                                   collection_name + '.tfrecord')\n",
    "        output_dir = pipelines_config['data_target_dir']\n",
    "        \n",
    "        # Construct the pipeline graph\n",
    "        pipeline_graph = build_pipeline_graph(\n",
    "            collection_name = collection_name,\n",
    "            config = pipelines_config\n",
    "        )\n",
    "\n",
    "        # Runs pipeline graph on a data source and writes output to dir\n",
    "        run_pipeline_text(\n",
    "            pipeline_graph,\n",
    "            pipeline.tf_record_iterator(src_file,\n",
    "                                        pipeline_graph.input_type),\n",
    "            output_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab():\n",
    "    \n",
    "    file_path = pipelines_config['data_target_dir'] + 'vocab.txt'\n",
    "    \n",
    "    vocab = {\n",
    "        'ON': (0, 127 + 1),\n",
    "        'OFF': (0, 127 + 1),\n",
    "        'SHIFT': (0, pipelines_config['steps_per_second'] + 1),\n",
    "    }  \n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(\"INFO: File {} exists. Removing. Rebuilding vocabulary.\".format(file_path))\n",
    "        os.remove(file_path)\n",
    "    with open(file_path, 'a') as file:\n",
    "        for action in vocab.keys():\n",
    "            for val in range(vocab[action][0], vocab[action][1]):\n",
    "                file.write(action + str(val) + '\\n')\n",
    "                \n",
    "    print(\"INFO: Vocabulary built.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run below to build your dataset\n",
    "\n",
    "This will create 6 files, two sets of train, evaluate and test. The first set is the inputs, and the second set is the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 88 inputs total. Produced 88 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_inputs_performance_lengths_in_seconds:\n",
      "  [20,30): 3\n",
      "  [30,40): 4\n",
      "  [40,60): 1\n",
      "  [60,120): 3\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_inputs_performance_lengths_in_seconds:\n",
      "  [5,10): 1\n",
      "  [10,20): 1\n",
      "  [30,40): 5\n",
      "  [40,60): 4\n",
      "  [60,120): 2\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_inputs_performance_lengths_in_seconds:\n",
      "  [5,10): 1\n",
      "  [10,20): 14\n",
      "  [20,30): 9\n",
      "  [30,40): 18\n",
      "  [40,60): 10\n",
      "  [60,120): 10\n",
      "  [120,inf): 2\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_eval_arrangement_inputs_count: 11\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_test_arrangement_inputs_count: 13\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_train_arrangement_inputs_count: 64\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 88 inputs total. Produced 88 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_targets_performance_lengths_in_seconds:\n",
      "  [10,20): 10\n",
      "  [20,30): 1\n",
      "  [30,40): 1\n",
      "  [40,60): 1\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_arrangement_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_targets_performance_lengths_in_seconds:\n",
      "  [10,20): 3\n",
      "  [20,30): 3\n",
      "  [30,40): 2\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_arrangement_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_targets_performance_lengths_in_seconds:\n",
      "  [5,10): 6\n",
      "  [10,20): 26\n",
      "  [20,30): 15\n",
      "  [30,40): 15\n",
      "  [40,60): 2\n",
      "  [60,120): 3\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_arrangement_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_eval_arrangement_targets_count: 13\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_test_arrangement_targets_count: 8\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_train_arrangement_targets_count: 67\n"
     ]
    }
   ],
   "source": [
    "create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: File ./data/performance_seq_text/vocab.txt exists. Removing. Rebuilding vocabulary.\n",
      "INFO: Vocabulary built.\n"
     ]
    }
   ],
   "source": [
    "build_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful IO\n",
    "\n",
    "##### Read `.tfrecord` of NoteSequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = './data/note_seqs/inputs.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = list()\n",
    "for record in pipeline.tf_record_iterator(tfrecord_path, music_pb2.NoteSequence):\n",
    "    records.append(record)\n",
    "\n",
    "# Hint: To look at first record, run `records[0]`\n",
    "# Hint 2: This is useful to drill inside: records[0].feature_lists.feature_list['inputs'].feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiate pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.models.performance_rnn import performance_model\n",
    "from magenta.pipelines import note_sequence_pipelines\n",
    "\n",
    "config = constants.default_configs['performance']\n",
    "\n",
    "quantizer_instance = note_sequence_pipelines.Quantizer(steps_per_second = config.steps_per_second,\n",
    "                                                       name='Quantizer_jupyter')\n",
    "perf_extractor_instance = PerformanceExtractor(num_velocity_bins = config.num_velocity_bins)\n",
    "encoder_pipeline_instance = EncoderPipeline(config,\n",
    "                                            name='EncoderPipeline_jupyter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-through pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in pipeline.tf_record_iterator(tfrecord_path, music_pb2.NoteSequence):\n",
    "    note_sequence1 = record\n",
    "# note_sequence1.SerializeToString()\n",
    "# note_sequence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence2 = quantizer_instance.transform(note_sequence1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence3 = perf_extractor_instance.transform(note_sequence2)[0]\n",
    "\n",
    "# note_sequence3.to_sequence()        # converts Performance to NoteSequence proto\n",
    "# note_sequence3.__getitem__(4)       # return event at position\n",
    "# note_sequence3.steps_per_second     # if Performance(BasePerformance)\n",
    "# note_sequence3.steps_per_quarter    # if MetricPerformance(BasePerformance)\n",
    "# note_sequence3._events              # list of all events\n",
    "# len(note_sequence3._events)         # len of events\n",
    "# note_sequence3.num_steps            # len of sequence in quantized steps\n",
    "# note_sequence3.steps                # list of the time step at each event in the sequence\n",
    "\n",
    "# returns an iterator\n",
    "# for i, event in enumerate(note_sequence3.__iter__()): \n",
    "#     print(event)\n",
    "#     if i > 25:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence4 = encoder_pipeline_instance.transform(note_sequence3)[0]\n",
    "# note_sequence4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining which position is 1 in the one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_event_ranges = [\n",
    "    (1, 1, 127),\n",
    "    (2, 1, 127),\n",
    "    (3, 1, 100)\n",
    "]\n",
    "\n",
    "def encode_event(event):\n",
    "    offset = 0\n",
    "    for event_type, min_value, max_value in _event_ranges:\n",
    "        if event[0] == event_type:\n",
    "            return offset + event[1] - min_value\n",
    "        offset += max_value - min_value + 1\n",
    "\n",
    "encode_event((3, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate time-shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
