{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will help you define and run pipelines to process your data. This includes data augmentation, slicing, stretching and encoding among others. If you want to use this notebook, you are expected to have already collated your original `.xml` with the help of `1.1. Collate Files.ipynb`.\n",
    "\n",
    "Pipelines are a data processing module which transforms input data types to output data types. The idea as well as bits & pieces are borrowed [the Magenta project](https://github.com/tensorflow/magenta/tree/master/magenta/pipelines).\n",
    "\n",
    "\n",
    "**INSTRUCTIONS**\n",
    " \n",
    "First, adjust the definition of the pipelines inside `pipeline_graph_def`. Then run `build_dataset`. This will create 4 files, two sets of train and evaluate. The first set is the inputs, and the second set is the targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEPENDENCIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import re \n",
    "import pandas as pd\n",
    "\n",
    "# The processing manager which glues everything\n",
    "from utils import data_processing\n",
    "\n",
    "# For Augmentation\n",
    "from utils.data_processing import TransposerToC, TransposerToRange, Reverser\n",
    "\n",
    "# For Processing\n",
    "from magenta.pipelines.note_sequence_pipelines import Quantizer, Splitter\n",
    "from utils.data_processing import PerformanceExtractor, MetadataExtractor, ParserToText\n",
    "\n",
    "# Other\n",
    "from magenta.protobuf import music_pb2\n",
    "from magenta.pipelines import pipelines_common, dag_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = dict()\n",
    "\n",
    "pipeline_config['data_source_dir'] = \"./data/collated/B/\"\n",
    "pipeline_config['data_target_dir'] = \"./data/processed/plover/\"\n",
    "\n",
    "# How many steps per quarter note\n",
    "pipeline_config['steps_per_quarter'] = 4\n",
    "\n",
    "pipeline_config['min_events'] = 1\n",
    "pipeline_config['max_events'] = 10000\n",
    "\n",
    "pipeline_config['MIN_MIDI_PITCH'] = 0 # Inclusive.\n",
    "pipeline_config['MAX_MIDI_PITCH'] = 127 # Inclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINITIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_graph_def(collection_name,\n",
    "                       config):\n",
    "    \"\"\"Returns the Pipeline instance which creates the RNN dataset.\n",
    "\n",
    "    Args:\n",
    "        collection_name:\n",
    "        config: dict() with configuration settings\n",
    "\n",
    "    Returns:\n",
    "        A pipeline.Pipeline instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # User Variables\n",
    "    metadata_df = pd.read_csv(os.path.join(pipeline_config['data_source_dir'], 'filex_index.csv'), index_col=0)\n",
    "    metadata_attr = ['segment', 'mode', 'genre', 'key', 'time_sig']\n",
    "    split_hop_size_seconds = 9999\n",
    "    \n",
    "    # Do Not Modify those\n",
    "    train_mode = re.match(r'train(?=_)', collection_name)\n",
    "    key = collection_name\n",
    "    dag = {}\n",
    "    \n",
    "    # Input must NOT be quantized\n",
    "    splitter = Splitter(\n",
    "        hop_size_seconds=split_hop_size_seconds,\n",
    "        name='Splitter_' + key)\n",
    "    \n",
    "    # `Quantizer` takes note data in seconds and snaps, or quantizes, \n",
    "    # everything to a discrete grid of timesteps. It maps `NoteSequence` \n",
    "    # protocol buffers to `NoteSequence` protos with quanitzed times. \n",
    "    quantizer = Quantizer(\n",
    "        steps_per_quarter=pipeline_config['steps_per_quarter'], \n",
    "        name='Quantizer_' + key)\n",
    "        # input_type=music_pb2.NoteSequence\n",
    "        # output_type=music_pb2.NoteSequence\n",
    "        \n",
    "    reverser = Reverser(\n",
    "        True if train_mode else False, \n",
    "        name='Reverser' + key)\n",
    "        # input_type=music_pb2.NoteSequence\n",
    "        # output_type=music_pb2.NoteSequence\n",
    "\n",
    "#     transposer = TransposerToRange(\n",
    "#         range(-12, 12) if train_mode else [0],\n",
    "#         min_pitch = pipeline_config['MIN_MIDI_PITCH'],\n",
    "#         max_pitch = pipeline_config['MAX_MIDI_PITCH'],\n",
    "#         name='Transposer_' + key)\n",
    "#         # input_type=music_pb2.NoteSequence\n",
    "#         # output_type=music_pb2.NoteSequence\n",
    "        \n",
    "    transposerToC = TransposerToC(\n",
    "        name='TransposerToC' + key)\n",
    "\n",
    "    perf_extractor = PerformanceExtractor(\n",
    "        min_events=pipeline_config['min_events'],\n",
    "        max_events=pipeline_config['max_events'],\n",
    "        num_velocity_bins=0,\n",
    "        name='PerformanceExtractor_' + key)\n",
    "        # input_type = music_pb2.NoteSequence\n",
    "        # output_type = magenta.music.MetricPerformance\n",
    "\n",
    "    meta_extractor = MetadataExtractor(\n",
    "        metadata_df = metadata_df,\n",
    "        attributes=metadata_attr,\n",
    "        name = 'MetadataExtractor' + key)\n",
    "    \n",
    "    parser = ParserToText(\n",
    "        name='ParserToText' + key)\n",
    "        # input_type = magenta.music.MetricPerformance\n",
    "        # output_type = str\n",
    "\n",
    "    # Reverse\n",
    "    # Split\n",
    "    \n",
    "    ### Pipelines Map ###\n",
    "    #\n",
    "    # DagInput > Splitter > Quantizer > Reverser > TransposerToC > PerformanceExtractor > 'MetricPerformance'\n",
    "    # DagInput > MetadataExtractor > 'metadata'\n",
    "    # \n",
    "    # {'MetricPerformance', 'meta'} > ParserToText > DagOutput\n",
    "    #\n",
    "    # Also available: TransposerToRange (for augmentation)\n",
    "    \n",
    "    dag[splitter] = dag_pipeline.DagInput(music_pb2.NoteSequence)\n",
    "    dag[quantizer] = splitter\n",
    "    dag[reverser] = quantizer\n",
    "    dag[transposerToC] = reverser\n",
    "    dag[perf_extractor] = transposerToC\n",
    "    \n",
    "    dag[meta_extractor] = dag_pipeline.DagInput(music_pb2.NoteSequence)\n",
    "    dag[parser] = meta_extractor\n",
    "    \n",
    "    dag[parser] = { 'MetricPerformance' : perf_extractor, \n",
    "                    'metadata' : meta_extractor }\n",
    "    \n",
    "    dag[dag_pipeline.DagOutput(key)] = parser\n",
    "        \n",
    "    return dag_pipeline.DAGPipeline(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Collated data sourced from ./data/collated/B/.\n",
      "\n",
      "INFO: Building train_inputs dataset...\n",
      "INFO: Augmenting by reversing.\n",
      "INFO: Transposing all to C.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 2540 inputs total. Produced 41584 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performance_lengths_in_bars:\n",
      "  [-inf,1): 3336\n",
      "  [1,10): 38248\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToCtrain_inputs_transpositions_generated: 41584\n",
      "\n",
      "INFO: Building train_targets dataset...\n",
      "INFO: Augmenting by reversing.\n",
      "INFO: Transposing all to C.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 2540 inputs total. Produced 28640 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performance_lengths_in_bars:\n",
      "  [-inf,1): 1700\n",
      "  [1,10): 26940\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToCtrain_targets_transpositions_generated: 28640\n",
      "\n",
      "INFO: Building eval_targets dataset...\n",
      "INFO: Transposing all to C.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 356 inputs total. Produced 1660 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performance_lengths_in_bars:\n",
      "  [-inf,1): 125\n",
      "  [1,10): 1535\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToCeval_targets_transpositions_generated: 1660\n",
      "\n",
      "INFO: Building eval_inputs dataset...\n",
      "INFO: Transposing all to C.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 356 inputs total. Produced 2585 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performance_lengths_in_bars:\n",
      "  [-inf,1): 255\n",
      "  [1,10): 2330\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToCeval_inputs_transpositions_generated: 2585\n",
      "\n",
      "INFO: Building test_targets dataset...\n",
      "INFO: Transposing all to C.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 343 inputs total. Produced 1697 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performance_lengths_in_bars:\n",
      "  [-inf,1): 134\n",
      "  [1,10): 1563\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToCtest_targets_transpositions_generated: 1697\n",
      "\n",
      "INFO: Building test_inputs dataset...\n",
      "INFO: Transposing all to C.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 343 inputs total. Produced 2603 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performance_lengths_in_bars:\n",
      "  [-inf,1): 205\n",
      "  [1,10): 2398\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToCtest_inputs_transpositions_generated: 2603\n"
     ]
    }
   ],
   "source": [
    "data_processing.build_dataset(pipeline_config, pipeline_graph_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Collecting tokens from ./data/processed/plover/train_inputs.txt\n",
      "INFO: Collecting tokens from ./data/processed/plover/train_targets.txt\n",
      "INFO: Vocabulary built.\n",
      "INFO: Tokens collected {'ON7', 'ON119', 'OFF14', 'OFF70', 'OFF30', 'OFF24', 'OFF38', 'OFF117', 'OFF123', 'ON44', '6over4', 'OFF40', 'OFF122', 'OFF5', 'ON51', 'OFF6', 'OFF71', 'OFF72', 'ON84', 'OFF74', 'SHIFT10', 'OFF61', 'ON24', 'ON97', 'ON110', 'OFF19', 'OFF4', 'OFF63', 'OFF125', 'ON87', 'OFF82', 'SHIFT15', 'outro', 'Contemporary', 'OFF97', 'ON5', 'ON39', 'F', 'ON81', 'OFF32', 'Db', 'ON67', 'OFF7', 'ON18', 'OFF3', 'ON103', 'OFF41', 'Bb', 'ON54', 'instrumental', 'OFF108', 'ON73', 'SHIFT6', 'ON109', 'OFF84', 'OFF2', 'ON11', 'ON78', 'OFF39', 'OFF56', 'OFF20', 'ON40', 'rap', 'OFF33', 'ON125', 'SHIFT1', 'ON43', 'ON36', 'OFF78', 'OFF115', 'ON74', 'ON22', 'ON120', 'OFF76', 'OFF54', 'OFF60', 'Religious', 'OFF64', 'SHIFT4', 'SHIFT7', 'OFF102', 'SHIFT9', 'OFF89', 'ON102', 'ON32', 'OFF34', 'prechorus', 'ON35', 'ON86', 'Gb', 'ON47', 'ON112', 'OFF67', 'OFF90', 'OFF83', 'OFF110', 'postchorus', 'ON38', 'OFF22', 'OFF0', 'ON4', 'OFF59', 'ON41', 'OFF107', 'ON75', 'Eb', 'ON6', 'OFF17', 'ON29', 'OFF43', 'OFF105', 'OFF8', 'OFF37', 'OFF44', 'OFF18', 'OFF1', 'OFF93', 'ON69', 'ON56', 'OFF31', 'ON21', 'OFF92', 'OFF111', 'ON94', 'OFF91', 'OFF118', 'ON105', 'SHIFT11', 'D', 'Country', 'ON88', 'ON34', 'SHIFT8', 'ON98', 'ON99', 'ON95', 'ON117', 'Ab', 'SHIFT3', 'ON92', 'OFF126', '6over8', 'ON79', '2over2', '12over8', 'OFF21', 'SHIFT13', 'OFF79', 'OFF35', 'ON118', 'ON52', 'ON60', 'ON13', 'ON71', 'ON63', 'ON1', 'ON113', 'ON49', 'OFF15', 'OFF75', 'OFF96', 'ON122', 'G', 'ON83', 'OFF28', 'OFF49', 'OFF50', 'OFF51', 'SHIFT0', 'ON53', 'ON48', 'OFF23', 'ON114', 'OFF57', 'OFF46', 'OFF68', 'OFF77', 'OFF81', '3over2', 'ON68', 'ON25', 'maj', 'OFF119', 'ON80', 'OFF100', 'OFF85', 'section', 'OFF13', 'ON59', 'OFF12', 'ON127', 'ON96', 'OFF66', 'ON70', 'ON93', 'SHIFT16', 'ON9', 'OFF48', 'ON12', 'ON72', 'OFF27', '3over4', 'chorus', 'ON23', 'E', 'ON16', 'OFF120', '4over4', 'ON30', 'ON66', 'ON8', 'ON19', 'OFF106', 'OFF124', 'ON0', 'ON17', 'ON90', 'OFF69', 'OFF99', 'OFF88', 'OFF103', 'C', 'Piano', 'ON55', 'ON15', 'intro', 'OFF109', 'ON111', 'ON91', 'OFF10', 'ON20', 'ON45', 'OFF80', 'SHIFT5', 'ON3', 'OFF16', 'ON89', 'OFF62', 'ON37', 'ON46', 'ON104', 'OFF86', 'OFF94', 'Rock', 'OFF9', 'ON50', 'ON76', 'OFF58', 'OFF52', 'OFF113', 'ON101', 'ON123', 'OFF36', 'ON26', 'OFF121', 'ON124', 'OFF26', 'ON121', 'OFF42', 'ON61', 'ON62', 'ON57', 'ON64', 'OFF11', 'OFF73', 'OFF55', 'OFF112', 'ON100', 'Musical', 'ON116', 'ON31', 'OFF101', 'OFF95', 'ON27', 'OFF104', 'ON107', 'OFF87', 'verse', 'ON42', 'ON58', 'ON14', 'ON77', 'ON82', 'OFF29', 'OFF114', 'SHIFT14', 'Cb', 'OFF127', 'OFF98', 'OFF47', 'Traditional', 'ON106', 'ON33', 'ON115', 'OFF45', 'SHIFT2', 'Pop', 'bridge', 'SHIFT12', 'ON108', 'ON10', 'ON65', 'ON85', 'min', 'ON126', 'OFF116', 'A', 'Film', 'OFF25', 'ON2', 'OFF65', 'OFF53', 'ON28'}\n"
     ]
    }
   ],
   "source": [
    "data_processing.build_vocab(pipeline_config,\n",
    "                            source_vocab_from=['train_inputs.txt', 'train_targets.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
