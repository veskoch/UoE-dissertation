{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will help you define and run pipelines to process your data. This includes data augmentation, slicing, stretching and encoding among others. If you want to use this notebook, you are expected to have already collated your original `.xml` with the help of `1.1. Collate Files.ipynb`.\n",
    "\n",
    "Pipelines are a data processing module which transforms input data types to output data types. The idea as well as bits & pieces are borrowed [the Magenta project](https://github.com/tensorflow/magenta/tree/master/magenta/pipelines).\n",
    "\n",
    "\n",
    "**INSTRUCTIONS**\n",
    " \n",
    "First, adjust the definition of the pipelines inside `pipeline_graph_def`. Then run `build_dataset`. This will create 4 files, two sets of train and evaluate. The first set is the inputs, and the second set is the targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEPENDENCIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import data_processing\n",
    "from utils.data_processing import PerformanceExtractor, PerformanceParser, TranspositionPipeline\n",
    "\n",
    "from magenta.protobuf import music_pb2\n",
    "from magenta.pipelines import pipelines_common, dag_pipeline, note_sequence_pipelines\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = dict()\n",
    "\n",
    "pipeline_config['data_source_dir'] = \"./data/collated/A/\"\n",
    "pipeline_config['data_target_dir'] = \"./data/processed/heron/\"\n",
    "\n",
    "# How many steps per quarter note\n",
    "pipeline_config['steps_per_quarter'] = 4\n",
    "\n",
    "pipeline_config['min_events'] = 1\n",
    "\n",
    "pipeline_config['max_events'] = 10000\n",
    "\n",
    "# Inclusive.\n",
    "pipeline_config['MIN_MIDI_PITCH'] = 0\n",
    "\n",
    "# Inclusive.\n",
    "pipeline_config['MAX_MIDI_PITCH'] = 127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINITIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_graph_def(collection_name,\n",
    "                       config):\n",
    "    \"\"\"Returns the Pipeline instance which creates the RNN dataset.\n",
    "\n",
    "    Args:\n",
    "        collection_name:\n",
    "        config: dict() with configuration settings\n",
    "\n",
    "    Returns:\n",
    "        A pipeline.Pipeline instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transpose no more than a major third.\n",
    "    transposition_range = range(-12, 12)\n",
    "    \n",
    "    train_mode = re.match(r'train(?=_)', collection_name)\n",
    "    \n",
    "    key = collection_name\n",
    "\n",
    "    dag = {}\n",
    "    \n",
    "    quantizer = note_sequence_pipelines.Quantizer(\n",
    "        steps_per_quarter=pipeline_config['steps_per_quarter'], \n",
    "        name='Quantizer_' + key)\n",
    "        # `Quantizer` takes note data in seconds and snaps, or quantizes, \n",
    "        # everything to a discrete grid of timesteps. It maps `NoteSequence` \n",
    "        # protocol buffers to `NoteSequence` protos with quanitzed times. \n",
    "        #\n",
    "        # input_type=music_pb2.NoteSequence\n",
    "        # output_type=music_pb2.NoteSequence\n",
    "\n",
    "    transposer = TranspositionPipeline(\n",
    "        transposition_range if train_mode else [0],\n",
    "        min_pitch = pipeline_config['MIN_MIDI_PITCH'],\n",
    "        max_pitch = pipeline_config['MAX_MIDI_PITCH'],\n",
    "        name='Transposer_' + key)\n",
    "        # input_type=music_pb2.NoteSequence\n",
    "        # output_type=music_pb2.NoteSequence\n",
    "\n",
    "    perf_extractor = PerformanceExtractor(\n",
    "        min_events=pipeline_config['min_events'],\n",
    "        max_events=pipeline_config['max_events'],\n",
    "        num_velocity_bins=0,\n",
    "        name='PerformanceExtractor_' + key)\n",
    "        # input_type = music_pb2.NoteSequence\n",
    "        # output_type = magenta.music.MetricPerformance\n",
    "\n",
    "    perf_parser = PerformanceParser(\n",
    "        name='PerformanceParser_' + key)\n",
    "        # input_type = magenta.music.MetricPerformance\n",
    "        # output_type = str\n",
    "\n",
    "    # Reverse\n",
    "    # Meter\n",
    "    \n",
    "    # In > Quantize > Transpose > Extract Performance > Parse to text > Out\n",
    "    dag[quantizer] = dag_pipeline.DagInput(music_pb2.NoteSequence)\n",
    "    dag[transposer] = quantizer\n",
    "    dag[perf_extractor] = transposer\n",
    "    dag[perf_parser] = perf_extractor\n",
    "    dag[dag_pipeline.DagOutput(key)] = perf_parser\n",
    "        \n",
    "    return dag_pipeline.DAGPipeline(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Building train_inputs dataset... Please wait...\n",
      "Transposition range range(-12, 12)\n",
      "Transposition pipeline ignores Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 2540 inputs total. Produced 60960 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performance_lengths_in_bars:\n",
      "  [-inf,1): 264\n",
      "  [1,10): 13008\n",
      "  [10,20): 27192\n",
      "  [20,30): 8760\n",
      "  [30,40): 9480\n",
      "  [40,50): 1584\n",
      "  [50,100): 672\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_train_inputs_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_train_inputs_transpositions_generated: 60960\n",
      "\n",
      "INFO: Building train_targets dataset... Please wait...\n",
      "Transposition range range(-12, 12)\n",
      "Transposition pipeline ignores Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 2540 inputs total. Produced 60960 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performance_lengths_in_bars:\n",
      "  [1,10): 24480\n",
      "  [10,20): 28752\n",
      "  [20,30): 5784\n",
      "  [30,40): 1584\n",
      "  [40,50): 216\n",
      "  [50,100): 144\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_train_targets_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_train_targets_transpositions_generated: 60960\n",
      "\n",
      "INFO: Building eval_targets dataset... Please wait...\n",
      "Transposition range [0]\n",
      "Transposition pipeline ignores Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 356 inputs total. Produced 356 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performance_lengths_in_bars:\n",
      "  [1,10): 219\n",
      "  [10,20): 112\n",
      "  [20,30): 10\n",
      "  [30,40): 15\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_eval_targets_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_eval_targets_transpositions_generated: 356\n",
      "\n",
      "INFO: Building eval_inputs dataset... Please wait...\n",
      "Transposition range [0]\n",
      "Transposition pipeline ignores Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 356 inputs total. Produced 356 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performance_lengths_in_bars:\n",
      "  [-inf,1): 2\n",
      "  [1,10): 106\n",
      "  [10,20): 155\n",
      "  [20,30): 39\n",
      "  [30,40): 46\n",
      "  [40,50): 4\n",
      "  [50,100): 4\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_eval_inputs_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_eval_inputs_transpositions_generated: 356\n",
      "\n",
      "INFO: Building test_targets dataset... Please wait...\n",
      "Transposition range [0]\n",
      "Transposition pipeline ignores Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 343 inputs total. Produced 343 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performance_lengths_in_bars:\n",
      "  [1,10): 181\n",
      "  [10,20): 125\n",
      "  [20,30): 34\n",
      "  [30,40): 3\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_test_targets_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_test_targets_transpositions_generated: 343\n",
      "\n",
      "INFO: Building test_inputs dataset... Please wait...\n",
      "Transposition range [0]\n",
      "Transposition pipeline ignores Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 343 inputs total. Produced 343 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performance_lengths_in_bars:\n",
      "  [1,10): 77\n",
      "  [10,20): 171\n",
      "  [20,30): 36\n",
      "  [30,40): 38\n",
      "  [40,50): 16\n",
      "  [50,100): 5\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_test_inputs_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_Transposer_test_inputs_transpositions_generated: 343\n"
     ]
    }
   ],
   "source": [
    "data_processing.build_dataset(pipeline_config, pipeline_graph_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Vocabulary built.\n"
     ]
    }
   ],
   "source": [
    "data_processing.build_vocab(pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-eaf45d5b957c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrouge_evaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROUGEEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/toy-ende/tgt-val.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data/toy-ende/tgt-val.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/opennmt/utils/evaluator.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, labels_file, predictions_path)\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mrouge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFilesRouge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mfiles_rouge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFilesRouge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mrouge_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles_rouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrouge_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hyp_path, ref_path, metrics, stats, batch_lines)\u001b[0m\n\u001b[1;32m     10\u001b[0m     def __init__(self, hyp_path, ref_path, metrics=None, stats=None,\n\u001b[1;32m     11\u001b[0m                  batch_lines=None):\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
