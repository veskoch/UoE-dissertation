{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will help you define and run pipelines to process your data. This includes data augmentation, slicing, stretching and encoding among others. If you want to use this notebook, you are expected to have already collated your original `.xml` with the help of `1.1. Collate Files.ipynb`.\n",
    "\n",
    "Pipelines are a data processing module which transforms input data types to output data types. The idea as well as bits & pieces are borrowed [the Magenta project](https://github.com/tensorflow/magenta/tree/master/magenta/pipelines).\n",
    "\n",
    "\n",
    "**INSTRUCTIONS**\n",
    " \n",
    "First, adjust the definition of the pipelines inside `pipeline_graph_def`. Then run `build_dataset`. This will create 4 files, two sets of train and evaluate. The first set is the inputs, and the second set is the targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEPENDENCIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'arranger_pipelines' from '/Users/vesko/GitHub/UoE-dissertation/model/build_dataset/arranger_pipelines.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arranger_pipelines\n",
    "import importlib\n",
    "importlib.reload(arranger_pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import re \n",
    "import pandas as pd\n",
    "\n",
    "# The processing manager which glues everything\n",
    "import arranger_pipelines\n",
    "\n",
    "# Augmentation Pipelines\n",
    "from arranger_pipelines import TransposerToC, TransposerToRange, Reverser\n",
    "\n",
    "# Processing Pipelines\n",
    "from magenta.pipelines.note_sequence_pipelines import Quantizer, Splitter\n",
    "from arranger_pipelines import PerformanceExtractor, MetadataExtractor, ParserToText, QuantizedSplitter\n",
    "\n",
    "# Other\n",
    "from magenta.protobuf import music_pb2\n",
    "from magenta.pipelines import dag_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = dict()\n",
    "\n",
    "pipeline_config['data_source_dir'] = \"../assets/data/collated/M/\"\n",
    "pipeline_config['data_target_dir'] = \"../assets/data/processed/_stats/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many steps per quarter note\n",
    "pipeline_config['steps_per_quarter'] = 4\n",
    "\n",
    "pipeline_config['min_events'] = 1\n",
    "pipeline_config['max_events'] = 9999999\n",
    "\n",
    "pipeline_config['MIN_MIDI_PITCH'] = 0 # Inclusive.\n",
    "pipeline_config['MAX_MIDI_PITCH'] = 126 # Inclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINITIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_graph_def(collection_name,\n",
    "                       config):\n",
    "    \"\"\"Returns the Pipeline instance which creates the RNN dataset.\n",
    "\n",
    "    Args:\n",
    "        collection_name:\n",
    "        config: dict() with configuration settings\n",
    "\n",
    "    Returns:\n",
    "        A pipeline.Pipeline instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # User Variables\n",
    "    metadata_df = pd.read_csv(os.path.join(pipeline_config['data_source_dir'], 'filex_index.csv'), index_col=0)\n",
    "    metadata_attr = []\n",
    "    split_hop_size_seconds = 99999\n",
    "    hop_bars = list(range(0, 70, 70)) # split every 3 bars, buffer up to 70 bars across all tracks\n",
    "    transpose_range = range(-24, 24)\n",
    "    transpose_range = [0]\n",
    "    \n",
    "    # Do Not Modify those\n",
    "    train_mode = re.match(r'train(?=_)', collection_name)\n",
    "    key = collection_name\n",
    "    \n",
    "    # Input must NOT be quantized\n",
    "    splitter = Splitter(\n",
    "        hop_size_seconds=split_hop_size_seconds,\n",
    "        name='Splitter_' + key)\n",
    "    \n",
    "    # `Quantizer` takes note data in seconds and snaps, or quantizes, \n",
    "    # everything to a discrete grid of timesteps. It maps `NoteSequence` \n",
    "    # protocol buffers to `NoteSequence` protos with quanitzed times. \n",
    "    quantizer = Quantizer(\n",
    "        steps_per_quarter=pipeline_config['steps_per_quarter'], \n",
    "        name='Quantizer_' + key)\n",
    "        # input_type=music_pb2.NoteSequence\n",
    "        # output_type=music_pb2.NoteSequence\n",
    "        \n",
    "    # Input MUST BE quantized\n",
    "    quant_splitter = QuantizedSplitter(\n",
    "        hop_bars=hop_bars,\n",
    "        metadata_df = metadata_df,\n",
    "        name='QuantizedSplitter_' + key)\n",
    "        \n",
    "    reverser = Reverser(\n",
    "        True if train_mode else False, \n",
    "        name='Reverser' + key)\n",
    "        # input_type=music_pb2.NoteSequence\n",
    "        # output_type=music_pb2.NoteSequence\n",
    "        \n",
    "    transposerToC = TransposerToC(\n",
    "        name='TransposerToC' + key,\n",
    "        min_valid_pitch = pipeline_config['MIN_MIDI_PITCH'],\n",
    "        max_valid_pitch = pipeline_config['MAX_MIDI_PITCH'])\n",
    "\n",
    "    transposer = TransposerToRange(\n",
    "        transpose_range if train_mode else [0],\n",
    "        min_pitch = pipeline_config['MIN_MIDI_PITCH'],\n",
    "        max_pitch = pipeline_config['MAX_MIDI_PITCH'],\n",
    "        name='TransposerToRange_' + key)\n",
    "        # input_type=music_pb2.NoteSequence\n",
    "        # output_type=music_pb2.NoteSequence\n",
    "\n",
    "    perf_extractor = PerformanceExtractor(\n",
    "        min_events=pipeline_config['min_events'],\n",
    "        max_events=pipeline_config['max_events'],\n",
    "        num_velocity_bins=0,\n",
    "        name='PerformanceExtractor_' + key)\n",
    "        # input_type = music_pb2.NoteSequence\n",
    "        # output_type = magenta.music.MetricPerformance\n",
    "\n",
    "    meta_extractor = MetadataExtractor(\n",
    "        metadata_df = metadata_df,\n",
    "        attributes=metadata_attr,\n",
    "        name = 'MetadataExtractor' + key)\n",
    "    \n",
    "    parser = ParserToText(\n",
    "        name='ParserToText' + key)\n",
    "        # input_type = magenta.music.MetricPerformance\n",
    "        # output_type = str\n",
    "\n",
    "    \n",
    "    ### Pipelines Full Map ###\n",
    "    #\n",
    "    # DagInput > Splitter > Quantizer > QuantizedSplitter > Reverser > TransposerToC > TransposerToRange > PerformanceExtractor > 'MetricPerformance'\n",
    "    # DagInput > MetadataExtractor > 'metadata'\n",
    "    # \n",
    "    # {'MetricPerformance', 'meta'} > ParserToText > DagOutput\n",
    "    #\n",
    "    \n",
    "    dag = {}\n",
    "    dag[quantizer] = dag_pipeline.DagInput(music_pb2.NoteSequence)\n",
    "    dag[quant_splitter] = quantizer\n",
    "    dag[reverser] = quant_splitter\n",
    "    dag[transposerToC] = reverser\n",
    "    dag[transposer] = transposerToC\n",
    "    dag[perf_extractor] = transposer\n",
    "    \n",
    "#     dag[quantizer] = dag_pipeline.DagInput(music_pb2.NoteSequence)\n",
    "#     dag[reverser] = quantizer\n",
    "#     dag[transposerToC] = reverser\n",
    "#     dag[transposer] = transposerToC\n",
    "#     dag[perf_extractor] = transposer\n",
    "    \n",
    "    dag[meta_extractor] = dag_pipeline.DagInput(music_pb2.NoteSequence)\n",
    "    \n",
    "    dag[parser] = { 'MetricPerformance' : perf_extractor, \n",
    "                    'metadata' : meta_extractor }\n",
    "    \n",
    "    dag[dag_pipeline.DagOutput(key)] = parser\n",
    "    \n",
    "    return dag_pipeline.DAGPipeline(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Target ../assets/data/processed/_stats/.\n",
      "INFO: Collated data sourced from ../assets/data/collated/M/.\n",
      "\n",
      "INFO: Building train_inputs dataset...\n",
      "INFO: Augmenting by reversing.\n",
      "INFO: Transposing all to C.\n",
      "INFO: Transposition [0]\n",
      "INFO: Transposition pipeline will ignore Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 4379 inputs total. Produced 17516 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performance_lengths_in_bars:\n",
      "  [-inf,1): 8790\n",
      "  [1,10): 2586\n",
      "  [10,20): 3994\n",
      "  [20,30): 1060\n",
      "  [30,40): 878\n",
      "  [40,50): 144\n",
      "  [50,100): 64\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_train_inputs_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_train_inputs_transpositions_generated: 17516\n",
      "\n",
      "INFO: Building train_targets dataset...\n",
      "INFO: Augmenting by reversing.\n",
      "INFO: Transposing all to C.\n",
      "INFO: Transposition [0]\n",
      "INFO: Transposition pipeline will ignore Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 4379 inputs total. Produced 17516 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performance_lengths_in_bars:\n",
      "  [-inf,1): 8758\n",
      "  [1,10): 3528\n",
      "  [10,20): 4126\n",
      "  [20,30): 826\n",
      "  [30,40): 228\n",
      "  [40,50): 30\n",
      "  [50,100): 20\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_train_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_train_targets_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_train_targets_transpositions_generated: 17516\n",
      "\n",
      "INFO: Building eval_targets dataset...\n",
      "INFO: Transposing all to C.\n",
      "INFO: Transposition [0]\n",
      "INFO: Transposition pipeline will ignore Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 612 inputs total. Produced 1224 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performance_lengths_in_bars:\n",
      "  [-inf,1): 612\n",
      "  [1,10): 376\n",
      "  [10,20): 193\n",
      "  [20,30): 18\n",
      "  [30,40): 25\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_eval_targets_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_eval_targets_transpositions_generated: 1224\n",
      "\n",
      "INFO: Building eval_inputs dataset...\n",
      "INFO: Transposing all to C.\n",
      "INFO: Transposition [0]\n",
      "INFO: Transposition pipeline will ignore Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 612 inputs total. Produced 1224 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performance_lengths_in_bars:\n",
      "  [-inf,1): 614\n",
      "  [1,10): 266\n",
      "  [10,20): 235\n",
      "  [20,30): 45\n",
      "  [30,40): 56\n",
      "  [40,50): 4\n",
      "  [50,100): 4\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_eval_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_eval_inputs_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_eval_inputs_transpositions_generated: 1224\n",
      "\n",
      "INFO: Building test_targets dataset...\n",
      "INFO: Transposing all to C.\n",
      "INFO: Transposition [0]\n",
      "INFO: Transposition pipeline will ignore Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 593 inputs total. Produced 1186 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performance_lengths_in_bars:\n",
      "  [-inf,1): 593\n",
      "  [1,10): 315\n",
      "  [10,20): 216\n",
      "  [20,30): 57\n",
      "  [30,40): 5\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_targets_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_test_targets_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_test_targets_transpositions_generated: 1186\n",
      "\n",
      "INFO: Building test_inputs dataset...\n",
      "INFO: Transposing all to C.\n",
      "INFO: Transposition [0]\n",
      "INFO: Transposition pipeline will ignore Key Signatures, Pitch Names and Chord Symbols.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 593 inputs total. Produced 1186 outputs.\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performance_lengths_in_bars:\n",
      "  [-inf,1): 593\n",
      "  [1,10): 214\n",
      "  [10,20): 263\n",
      "  [20,30): 55\n",
      "  [30,40): 40\n",
      "  [40,50): 16\n",
      "  [50,100): 5\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_discarded_more_than_1_program: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_PerformanceExtractor_test_inputs_performances_truncated_timewise: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_test_inputs_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_TransposerToRange_test_inputs_transpositions_generated: 1186\n"
     ]
    }
   ],
   "source": [
    "arranger_pipelines.build_dataset(pipeline_config, pipeline_graph_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Vocabulary built.\n",
      "INFO: Tokens collected {'OFF101', 'OFF45', 'OFF61', 'ON46', 'OFF94', 'OFF127', 'SHIFT3', 'ON95', 'ON26', 'OFF108', 'ON36', 'OFF42', 'ON73', 'OFF48', 'SHIFT8', 'OFF11', 'OFF80', 'OFF67', 'OFF36', 'ON103', 'ON127', 'OFF55', 'SHIFT9', 'ON18', 'ON9', 'ON3', 'OFF110', 'ON116', 'ON82', 'OFF50', 'ON19', 'OFF0', 'ON77', 'ON57', 'ON122', 'OFF31', 'OFF28', 'OFF93', 'ON17', 'OFF77', 'ON33', 'ON68', 'OFF69', 'ON8', 'OFF40', 'OFF105', 'ON12', 'ON72', 'SHIFT10', 'SHIFT12', 'OFF90', 'OFF104', 'SHIFT4', 'ON51', 'ON96', 'ON30', 'OFF24', 'ON80', 'ON31', 'ON83', 'OFF107', 'ON27', 'ON89', 'OFF122', 'SHIFT2', 'ON84', 'OFF39', 'ON37', 'OFF17', 'OFF27', 'OFF85', 'OFF121', 'OFF79', 'ON70', 'OFF43', 'OFF118', 'SHIFT13', 'ON4', 'OFF37', 'OFF76', 'OFF123', 'SHIFT5', 'ON71', 'ON21', 'OFF19', 'OFF72', 'ON108', 'ON118', 'OFF35', 'OFF89', 'ON40', 'OFF20', 'SHIFT15', 'ON126', 'OFF32', 'OFF65', 'OFF95', 'OFF8', 'OFF53', 'ON24', 'ON93', 'ON88', 'OFF68', 'OFF75', 'ON124', 'OFF14', 'OFF82', 'OFF34', 'ON79', 'OFF1', 'OFF29', 'OFF125', 'ON99', 'OFF98', 'ON10', 'OFF46', 'ON66', 'OFF4', 'OFF113', 'ON2', 'OFF91', 'SHIFT11', 'OFF23', 'ON61', 'ON76', 'ON64', 'ON7', 'OFF117', 'ON58', 'OFF100', 'OFF124', 'ON104', 'ON119', 'OFF73', 'ON65', 'ON67', 'OFF15', 'OFF47', 'OFF66', 'OFF26', 'ON5', 'OFF114', 'OFF86', 'OFF60', 'ON43', 'ON35', 'ON48', 'OFF10', 'SHIFT6', 'OFF102', 'OFF96', 'ON123', 'ON112', 'OFF56', 'ON38', 'ON106', 'ON107', 'OFF63', 'OFF70', 'ON69', 'OFF78', 'ON110', 'OFF88', 'ON86', 'OFF97', 'OFF71', 'OFF16', 'ON121', 'ON6', 'ON22', 'SHIFT16', 'ON59', 'ON55', 'ON25', 'OFF109', 'ON42', 'ON91', 'OFF103', 'ON63', 'OFF115', 'OFF62', 'OFF33', 'OFF116', 'SHIFT1', 'OFF12', 'SHIFT0', 'SHIFT7', 'ON54', 'ON78', 'ON56', 'OFF120', 'OFF54', 'ON41', 'OFF2', 'OFF99', 'ON62', 'OFF7', 'OFF41', 'ON87', 'ON100', 'ON85', 'OFF59', 'OFF74', 'ON105', 'ON47', 'ON114', 'OFF5', 'OFF87', 'ON101', 'ON75', 'SHIFT14', 'ON20', 'OFF84', 'OFF3', 'ON90', 'OFF57', 'ON92', 'ON14', 'ON52', 'OFF25', 'OFF6', 'OFF111', 'OFF58', 'OFF112', 'ON34', 'ON16', 'ON29', 'ON98', 'OFF51', 'OFF119', 'ON120', 'ON102', 'ON28', 'OFF92', 'ON50', 'ON0', 'ON81', 'ON97', 'ON111', 'OFF64', 'OFF44', 'ON23', 'ON39', 'ON74', 'ON15', 'OFF18', 'ON125', 'OFF21', 'OFF81', 'ON109', 'ON11', 'ON13', 'ON45', 'ON94', 'OFF30', 'ON113', 'OFF106', 'ON53', 'OFF9', 'OFF22', 'OFF52', 'ON60', 'OFF126', 'ON44', 'OFF13', 'OFF38', 'ON115', 'ON117', 'ON32', 'ON49', 'ON1', 'OFF49', 'OFF83'}\n"
     ]
    }
   ],
   "source": [
    "# Uncomment if you want to prepend metadata tokens\n",
    "# arranger_pipelines.build_vocab(pipeline_config,\n",
    "#                             source_vocab_from=['train_inputs.txt', 'train_targets.txt'])\n",
    "arranger_pipelines.build_vocab(pipeline_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronously Remove Blank Lines in Two Files\n",
    "\n",
    "Necessary only if splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 2880 Empty line indices found in eval.\n",
      "INFO: Finished writing eval_inputs.txt\n",
      "INFO: Finished writing eval_targets.txt\n",
      "INFO: 1888224 Empty line indices found in train.\n",
      "INFO: Finished writing train_inputs.txt\n",
      "INFO: Finished writing train_targets.txt\n",
      "INFO: 2735 Empty line indices found in test.\n",
      "INFO: Finished writing test_inputs.txt\n",
      "INFO: Finished writing test_targets.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for dataset_type in ['eval', 'train', 'test']:\n",
    "    inputs_file_name = dataset_type +'_inputs.txt'\n",
    "    targets_file_name = dataset_type + '_targets.txt'\n",
    "\n",
    "    inputs_path = os.path.join(pipeline_config['data_target_dir'], inputs_file_name)\n",
    "    targets_path = os.path.join(pipeline_config['data_target_dir'], targets_file_name)\n",
    "\n",
    "    with open(inputs_path, 'r') as i, open(targets_path, 'r') as t:\n",
    "        inputs = [l for l in i.readlines()]\n",
    "        targets = [l for l in t.readlines()]\n",
    "\n",
    "    assert len(inputs) == len(targets)\n",
    "\n",
    "    to_remove = []\n",
    "    for i in range(len(inputs)):\n",
    "        if inputs[i] == '\\n' or targets[i] == '\\n':\n",
    "            to_remove.append(i)\n",
    "\n",
    "    print('INFO: {} Empty line indices found in {}.'.format(len(to_remove), dataset_type))\n",
    "    \n",
    "    # Write to disk\n",
    "    inputs_light = pd.Series(inputs).drop(to_remove)\n",
    "    targets_light = pd.Series(targets).drop(to_remove)\n",
    "\n",
    "    with open(os.path.join(pipeline_config['data_target_dir'], 'fixed', inputs_file_name), 'w') as f:\n",
    "        f.write(''.join(list(inputs_light)))\n",
    "    print('INFO: Finished writing {}'.format(inputs_file_name))\n",
    "    with open(os.path.join(pipeline_config['data_target_dir'], 'fixed', targets_file_name), 'w') as f:\n",
    "        f.write(''.join(list(targets_light)))\n",
    "    print('INFO: Finished writing {}'.format(targets_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
