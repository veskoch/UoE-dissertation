{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides statistical tools to evaluate the models quantitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/OpenNMT/VisTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at vizualizations of Sequential Neural Networks with Attention\n",
    "# https://github.com/HendrikStrobelt/Seq2Seq-Vis\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/44613173/how-to-visualize-attention-weights-from-attentionwrapper\n",
    "# Similar question: https://stackoverflow.com/questions/40601552/visualizing-attention-activation-in-tensorflow\n",
    "\n",
    "# Also look at textsum automatic summarization Seq2Seq-Attention models https://github.com/rockingdingo/deepnlp/#modules"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def beam_search(symbols_to_logits_fn,\n",
    "                initial_ids,\n",
    "                beam_size,\n",
    "                decode_length,\n",
    "                vocab_size,\n",
    "                alpha,\n",
    "                states=None,\n",
    "                eos_id=EOS_ID,\n",
    "                stop_early=True):\n",
    "  \"\"\"Beam search with length penalties.\n",
    "\n",
    "  Requires a function that can take the currently decoded symbols and return\n",
    "  the logits for the next symbol. The implementation is inspired by\n",
    "  https://arxiv.org/abs/1609.08144.\n",
    "\n",
    "  When running, the beam search steps can be visualized by using tfdbg to watch\n",
    "  the operations generating the output ids for each beam step.  These operations\n",
    "  have the pattern:\n",
    "    (alive|finished)_topk_(seq,scores)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IDEA: Visualize the SHIFT â€“ most will be averaging 2, highly skewed towards longer intervals. 16 is 1/16 shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can access attention weights by setting alignment_history=True flag in AttentionWrapper definition.\n",
    "\n",
    "# Define attention mechanism\n",
    "attn_mech = tf.contrib.seq2seq.LuongMonotonicAttention(\n",
    "    num_units = attention_unit_size, memory = decoder_outputs,\n",
    "    memory_sequence_length = input_lengths)\n",
    "\n",
    "# Define attention cell\n",
    "attn_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "    cell = decoder_cell, attention_mechanism = attn_mech,\n",
    "    alignment_history=True)\n",
    "\n",
    "# Define train helper\n",
    "train_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "    inputs = encoder_inputs, \n",
    "    sequence_length = input_lengths)\n",
    "\n",
    "# Define decoder\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    cell = attn_cell, \n",
    "    helper = train_helper, initial_state=decoder_initial_state)\n",
    "\n",
    "# Dynamic decoding\n",
    "dec_outputs, dec_states, _ = tf.contrib.seq2seq.dynamic_decode(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then inside the session, you can access the weights as below:\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ...\n",
    "    alignments = sess.run(dec_states.alignment_history.stack(), feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, you can visualize attentions (alignments) like this:\n",
    "\n",
    "def plot_attention(attention_map, input_tags = None, output_tags = None):    \n",
    "    attn_len = len(attention_map)\n",
    "\n",
    "    # Plot the attention_map\n",
    "    plt.clf()\n",
    "    f = plt.figure(figsize=(15, 10))\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "    # Add image\n",
    "    i = ax.imshow(attention_map, interpolation='nearest', cmap='Blues')\n",
    "\n",
    "    # Add colorbar\n",
    "    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
    "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
    "    cbar.ax.set_xlabel('Alpha value (Probability output of the \"softmax\")', labelpad=2)\n",
    "\n",
    "    # Add labels\n",
    "    ax.set_yticks(range(attn_len))\n",
    "    if output_tags != None:\n",
    "      ax.set_yticklabels(output_tags[:attn_len])\n",
    "\n",
    "    ax.set_xticks(range(attn_len))\n",
    "    if input_tags != None:\n",
    "      ax.set_xticklabels(input_tags[:attn_len], rotation=45)\n",
    "\n",
    "    ax.set_xlabel('Input Sequence')\n",
    "    ax.set_ylabel('Output Sequence')\n",
    "\n",
    "    # add grid and legend\n",
    "    ax.grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# input_tags - word representation of input sequence, use None to skip\n",
    "# output_tags - word representation of output sequence, use None to skip\n",
    "# i - index of input element in batch\n",
    "\n",
    "plot_attention(alignments[:, i, :], input_tags, output_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
